# SACToR Batch API ä¼˜åŒ–æ–¹æ¡ˆ

## é—®é¢˜åˆ†æ

### å½“å‰è°ƒç”¨æ¨¡å¼

SACToRåœ¨ç¿»è¯‘ä¸€ä¸ªCæ–‡ä»¶æ—¶ä¼šè¿›è¡Œ**å¤šæ¬¡ç‹¬ç«‹çš„LLMè°ƒç”¨**ï¼š

```
ç¿»è¯‘ä¸€ä¸ªCæ–‡ä»¶çš„æµç¨‹:
1. ç¿»è¯‘ enum        â†’ LLMè°ƒç”¨ 1
2. ç¿»è¯‘ struct      â†’ LLMè°ƒç”¨ 2
3. ç¿»è¯‘ function 1  â†’ LLMè°ƒç”¨ 3
4. ç¿»è¯‘ function 2  â†’ LLMè°ƒç”¨ 4
5. ç¿»è¯‘ function 3  â†’ LLMè°ƒç”¨ 5
6. éªŒè¯ harness     â†’ LLMè°ƒç”¨ 6
7. ä¿®å¤é”™è¯¯         â†’ LLMè°ƒç”¨ 7-N
...

æ€»è®¡: å¹³å‡ 10-20 æ¬¡ç‹¬ç«‹è°ƒç”¨
```

### æˆæœ¬é—®é¢˜

æ¯æ¬¡ç‹¬ç«‹è°ƒç”¨çš„é—®é¢˜ï¼š
- âŒ ç½‘ç»œå¾€è¿”å»¶è¿Ÿï¼ˆRTTï¼‰
- âŒ æ¯æ¬¡éƒ½å»ºç«‹è¿æ¥
- âŒ æ— æ³•åˆ©ç”¨æ‰¹é‡æŠ˜æ‰£
- âŒ ä¸²è¡Œå¤„ç†é€Ÿåº¦æ…¢

## Batch API æ–¹æ¡ˆ

### æ–¹æ¡ˆ1: OpenAI Batch API (å¼‚æ­¥æ‰¹å¤„ç†) â­

#### ç‰¹ç‚¹
- âœ… **50% æˆæœ¬æŠ˜æ‰£**
- âœ… 24å°æ—¶å†…å®Œæˆ
- âœ… é€‚åˆå¤§è§„æ¨¡æ‰¹é‡å¤„ç†
- âš ï¸ å¼‚æ­¥å¤„ç†ï¼Œéœ€è¦ç­‰å¾…

#### å·¥ä½œæµç¨‹

```
1. æ”¶é›†é˜¶æ®µ (1-2åˆ†é’Ÿ)
   â†“ æ”¶é›†æ‰€æœ‰å¾…ç¿»è¯‘çš„Cæ–‡ä»¶
   â†“ ç”Ÿæˆæ‰€æœ‰éœ€è¦çš„prompts
   
2. æäº¤Batch (å‡ ç§’)
   â†“ åˆ›å»ºJSONLæ–‡ä»¶
   â†“ ä¸Šä¼ åˆ°API
   â†“ è·å–batch_id
   
3. ç­‰å¾…å¤„ç† (å‡ åˆ†é’Ÿåˆ°å‡ å°æ—¶)
   â†“ è½®è¯¢çŠ¶æ€
   â†“ APIåå°æ‰¹é‡å¤„ç†
   
4. è·å–ç»“æœ (å‡ ç§’)
   â†“ ä¸‹è½½ç»“æœæ–‡ä»¶
   â†“ è§£æJSONL
   â†“ æ˜ å°„å›åŸå§‹è¯·æ±‚
```

#### æˆæœ¬å¯¹æ¯”

| æ¨¡å¼ | 500ä¸ªæ–‡ä»¶ | 10,000ä¸ªæ–‡ä»¶ |
|------|-----------|-------------|
| æ™®é€šAPI | $60.00 | $1,200.00 |
| **Batch API** | **$30.00** | **$600.00** |
| **èŠ‚çœ** | **$30.00 (50%)** | **$600.00 (50%)** |

---

### æ–¹æ¡ˆ2: è‡ªå®šä¹‰æ‰¹é‡èšåˆ (åŒæ­¥ä¼˜åŒ–)

#### ç‰¹ç‚¹
- âœ… ç«‹å³å¤„ç†
- âœ… å‡å°‘ç½‘ç»œå¼€é”€
- âš ï¸ æ— æˆæœ¬æŠ˜æ‰£
- âš ï¸ éœ€è¦é‡æ„ä»£ç 

#### ç­–ç•¥

**ç­–ç•¥A: åŒæ–‡ä»¶å†…æ‰¹é‡ç¿»è¯‘**

å°†ä¸€ä¸ªCæ–‡ä»¶çš„å¤šä¸ªå‡½æ•°åˆå¹¶åˆ°ä¸€ä¸ªpromptä¸­ï¼š

```python
# å½“å‰æ–¹å¼ï¼ˆ10æ¬¡è°ƒç”¨ï¼‰
translate(function1) â†’ result1
translate(function2) â†’ result2
...
translate(function10) â†’ result10

# ä¼˜åŒ–æ–¹å¼ï¼ˆ1æ¬¡è°ƒç”¨ï¼‰
translate([function1, function2, ..., function10]) â†’ [result1, result2, ..., result10]
```

**ä¼˜åŠ¿**:
- å‡å°‘90%çš„APIè°ƒç”¨æ¬¡æ•°
- æ›´å¿«çš„å¤„ç†é€Ÿåº¦
- å‡å°‘ç½‘ç»œå¾€è¿”

**ç­–ç•¥B: è·¨æ–‡ä»¶æ‰¹é‡ç¿»è¯‘**

å°†å¤šä¸ªCæ–‡ä»¶çš„ç¿»è¯‘åˆå¹¶ï¼š

```python
# å½“å‰æ–¹å¼ï¼ˆ500æ¬¡è°ƒç”¨ï¼‰
for file in files:
    translate(file)

# ä¼˜åŒ–æ–¹å¼ï¼ˆ1æ¬¡è°ƒç”¨ï¼‰
translate_batch(files) â†’ results
```

**é£é™©**:
- Promptå¯èƒ½è¿‡é•¿
- é”™è¯¯å½±å“æ•´æ‰¹
- éš¾ä»¥è°ƒè¯•

---

## æ¨èæ–¹æ¡ˆ: æ··åˆæ–¹æ¡ˆ â­â­â­

### ç­–ç•¥

1. **å°æ‰¹é‡å®æ—¶å¤„ç†** (< 50ä¸ªæ–‡ä»¶)
   - ä½¿ç”¨æ™®é€šAPI + Prompt Cache
   - ç«‹å³è·å¾—ç»“æœ
   
2. **å¤§æ‰¹é‡ç¦»çº¿å¤„ç†** (> 50ä¸ªæ–‡ä»¶)
   - ä½¿ç”¨Batch API
   - èŠ‚çœ50%æˆæœ¬
   - å¯ä»¥ç­‰å¾…

### å®æ–½æ–¹æ¡ˆ

#### é˜¶æ®µ1: Batch APIé›†æˆ

åˆ›å»º `batch_translate_with_batch_api.py`:

```python
import json
import time
from openai import OpenAI

class BatchAPITranslator:
    def __init__(self):
        self.client = OpenAI(
            api_key="sk-aaca0ccf722143a39ec3c6e38a0a4bc2",
            base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
        )
    
    def collect_translation_requests(self, c_files):
        """æ”¶é›†æ‰€æœ‰ç¿»è¯‘è¯·æ±‚"""
        requests = []
        
        for idx, c_file in enumerate(c_files):
            # è¯»å–Cä»£ç 
            with open(c_file, 'r') as f:
                c_code = f.read()
            
            # åˆ›å»ºè¯·æ±‚
            request = {
                "custom_id": f"translate-{idx}",
                "method": "POST",
                "url": "/v1/chat/completions",
                "body": {
                    "model": "qwen3-coder-plus",
                    "messages": [
                        {
                            "role": "system",
                            "content": "You are a C to Rust translator...",
                            "cache_control": {"type": "ephemeral"}
                        },
                        {
                            "role": "user",
                            "content": f"Translate this C code to Rust:\n\n{c_code}"
                        }
                    ],
                    "temperature": 0.3
                }
            }
            requests.append(request)
        
        return requests
    
    def create_batch_file(self, requests, output_path):
        """åˆ›å»ºJSONLæ ¼å¼çš„æ‰¹å¤„ç†æ–‡ä»¶"""
        with open(output_path, 'w') as f:
            for req in requests:
                f.write(json.dumps(req) + '\n')
    
    def submit_batch(self, batch_file_path):
        """æäº¤æ‰¹å¤„ç†ä»»åŠ¡"""
        # ä¸Šä¼ æ–‡ä»¶
        with open(batch_file_path, 'rb') as f:
            batch_file = self.client.files.create(
                file=f,
                purpose='batch'
            )
        
        # åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡
        batch = self.client.batches.create(
            input_file_id=batch_file.id,
            endpoint="/v1/chat/completions",
            completion_window="24h"
        )
        
        return batch.id
    
    def check_batch_status(self, batch_id):
        """æ£€æŸ¥æ‰¹å¤„ç†çŠ¶æ€"""
        batch = self.client.batches.retrieve(batch_id)
        return batch.status, batch
    
    def retrieve_results(self, batch_id):
        """è·å–æ‰¹å¤„ç†ç»“æœ"""
        batch = self.client.batches.retrieve(batch_id)
        
        if batch.status != "completed":
            raise Exception(f"Batch not completed: {batch.status}")
        
        # ä¸‹è½½ç»“æœæ–‡ä»¶
        result_file = self.client.files.content(batch.output_file_id)
        
        # è§£æç»“æœ
        results = []
        for line in result_file.text.split('\n'):
            if line.strip():
                results.append(json.loads(line))
        
        return results
    
    def batch_translate(self, c_files):
        """æ‰¹é‡ç¿»è¯‘ä¸»å‡½æ•°"""
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(c_files)} ä¸ªæ–‡ä»¶")
        
        # 1. æ”¶é›†è¯·æ±‚
        print("ğŸ“ æ”¶é›†ç¿»è¯‘è¯·æ±‚...")
        requests = self.collect_translation_requests(c_files)
        
        # 2. åˆ›å»ºæ‰¹å¤„ç†æ–‡ä»¶
        batch_file = "/tmp/batch_translate_requests.jsonl"
        print(f"ğŸ“„ åˆ›å»ºæ‰¹å¤„ç†æ–‡ä»¶: {batch_file}")
        self.create_batch_file(requests, batch_file)
        
        # 3. æäº¤æ‰¹å¤„ç†
        print("â¬†ï¸  æäº¤æ‰¹å¤„ç†ä»»åŠ¡...")
        batch_id = self.submit_batch(batch_file)
        print(f"âœ… æ‰¹å¤„ç†ID: {batch_id}")
        
        # 4. è½®è¯¢çŠ¶æ€
        print("â³ ç­‰å¾…å¤„ç†å®Œæˆ...")
        while True:
            status, batch = self.check_batch_status(batch_id)
            print(f"   çŠ¶æ€: {status}")
            
            if status == "completed":
                break
            elif status in ["failed", "expired", "cancelled"]:
                raise Exception(f"Batch failed with status: {status}")
            
            time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        # 5. è·å–ç»“æœ
        print("ğŸ“¥ ä¸‹è½½ç»“æœ...")
        results = self.retrieve_results(batch_id)
        
        print(f"âœ… å®Œæˆï¼å…± {len(results)} ä¸ªç»“æœ")
        return results
```

#### é˜¶æ®µ2: æ™ºèƒ½è·¯ç”±

æ ¹æ®ä»»åŠ¡è§„æ¨¡è‡ªåŠ¨é€‰æ‹©ï¼š

```python
def smart_translate(c_files, wait_for_batch=True):
    """æ™ºèƒ½é€‰æ‹©ç¿»è¯‘æ¨¡å¼"""
    
    if len(c_files) < 50 or not wait_for_batch:
        # å°æ‰¹é‡æˆ–éœ€è¦ç«‹å³ç»“æœï¼šä½¿ç”¨æ™®é€šAPI
        print("ğŸ“ ä½¿ç”¨å®æ—¶APIæ¨¡å¼")
        return realtime_translate(c_files)
    else:
        # å¤§æ‰¹é‡ï¼šä½¿ç”¨Batch API
        print("ğŸ“ ä½¿ç”¨Batch APIæ¨¡å¼ï¼ˆ50%æŠ˜æ‰£ï¼‰")
        return batch_api_translate(c_files)
```

---

## è¯¦ç»†å®æ–½è®¡åˆ’

### é˜¶æ®µ1: éªŒè¯Batch APIæ”¯æŒ (1å¤©)

#### ä»»åŠ¡
1. ç¡®è®¤Qwenæ˜¯å¦æ”¯æŒOpenAIå…¼å®¹çš„Batch API
2. åˆ›å»ºç®€å•çš„æµ‹è¯•è„šæœ¬
3. æäº¤å°æ‰¹é‡æµ‹è¯•ï¼ˆ5-10ä¸ªè¯·æ±‚ï¼‰

#### éªŒè¯è„šæœ¬

```python
# test_batch_api.py
from openai import OpenAI

client = OpenAI(
    api_key="sk-aaca0ccf722143a39ec3c6e38a0a4bc2",
    base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
)

# å°è¯•åˆ›å»ºbatch
try:
    # åˆ›å»ºæµ‹è¯•JSONL
    with open('/tmp/test_batch.jsonl', 'w') as f:
        f.write(json.dumps({
            "custom_id": "test-1",
            "method": "POST",
            "url": "/v1/chat/completions",
            "body": {
                "model": "qwen3-coder-plus",
                "messages": [{"role": "user", "content": "Hello"}]
            }
        }) + '\n')
    
    # ä¸Šä¼ æ–‡ä»¶
    with open('/tmp/test_batch.jsonl', 'rb') as f:
        batch_file = client.files.create(file=f, purpose='batch')
    
    # åˆ›å»ºbatch
    batch = client.batches.create(
        input_file_id=batch_file.id,
        endpoint="/v1/chat/completions",
        completion_window="24h"
    )
    
    print(f"âœ… Batch APIæ”¯æŒï¼Batch ID: {batch.id}")
    
except Exception as e:
    print(f"âŒ Batch APIä¸æ”¯æŒ: {e}")
```

### é˜¶æ®µ2: è®¾è®¡æ‰¹é‡èšåˆç­–ç•¥ (2å¤©)

#### æ–¹æ¡ˆA: å‡½æ•°çº§åˆ«æ‰¹é‡

```python
def translate_functions_batch(functions):
    """ä¸€æ¬¡æ€§ç¿»è¯‘å¤šä¸ªå‡½æ•°"""
    prompt = "Translate these C functions to Rust:\n\n"
    for i, func in enumerate(functions):
        prompt += f"=== Function {i+1} ===\n{func}\n\n"
    
    response = llm.query(prompt)
    
    # è§£æå¤šä¸ªå‡½æ•°çš„ç»“æœ
    return parse_multiple_functions(response)
```

**ä¼˜åŠ¿**: ç®€å•ï¼Œæ˜“äºå®ç°
**åŠ£åŠ¿**: Promptå¯èƒ½è¿‡é•¿

#### æ–¹æ¡ˆB: ä½¿ç”¨Batch API

**ä¼˜åŠ¿**: 50%æˆæœ¬èŠ‚çœ
**åŠ£åŠ¿**: å¼‚æ­¥ï¼Œéœ€è¦ç­‰å¾…

### é˜¶æ®µ3: å®ç°ä¸æµ‹è¯• (3-5å¤©)

1. å®ç°Batch APIå°è£…
2. ä¿®æ”¹SACToRç¿»è¯‘æµç¨‹
3. æ·»åŠ æ™ºèƒ½è·¯ç”±é€»è¾‘
4. æµ‹è¯•å°è§„æ¨¡ï¼ˆ10ä¸ªæ–‡ä»¶ï¼‰
5. æµ‹è¯•å¤§è§„æ¨¡ï¼ˆ500ä¸ªæ–‡ä»¶ï¼‰

### é˜¶æ®µ4: æ€§èƒ½å¯¹æ¯” (1å¤©)

å¯¹æ¯”ä¸‰ç§æ¨¡å¼ï¼š

| æ¨¡å¼ | 100ä¸ªæ–‡ä»¶ | æˆæœ¬ | æ—¶é—´ | æˆåŠŸç‡ |
|------|-----------|------|------|--------|
| å½“å‰æ–¹å¼ | - | $12 | 5å°æ—¶ | 72% |
| +Prompt Cache | - | $4 | 5å°æ—¶ | 72% |
| +Batch API | - | $2 | 30åˆ†é’Ÿ+2å°æ—¶ | 72% |

---

## æ³¨æ„äº‹é¡¹

### 1. Qwen Batch APIå¯ç”¨æ€§

**éœ€è¦ç¡®è®¤**:
- âœ… Qwenæ˜¯å¦æ”¯æŒOpenAIå…¼å®¹çš„Batch API
- âœ… æ˜¯å¦æœ‰50%æŠ˜æ‰£
- âœ… å¤„ç†æ—¶é—´é™åˆ¶

**å¦‚æœä¸æ”¯æŒ**: ä½¿ç”¨æ–¹æ¡ˆ2ï¼ˆè‡ªå®šä¹‰æ‰¹é‡èšåˆï¼‰

### 2. é”™è¯¯å¤„ç†

```python
# Batch APIçš„é”™è¯¯å¤„ç†
for result in batch_results:
    if result.get('error'):
        print(f"è¯·æ±‚ {result['custom_id']} å¤±è´¥: {result['error']}")
        # å›é€€åˆ°æ™®é€šAPI
        retry_with_realtime_api(result['custom_id'])
```

### 3. è°ƒè¯•å›°éš¾

Batch APIçš„è°ƒè¯•æ›´å›°éš¾ï¼š
- å¼‚æ­¥å¤„ç†ï¼Œæ— æ³•å®æ—¶çœ‹åˆ°ç»“æœ
- é”™è¯¯ä¿¡æ¯å¯èƒ½ä¸å¤Ÿè¯¦ç»†
- å»ºè®®ï¼šå…ˆç”¨å°æ‰¹é‡æµ‹è¯•

---

## æˆæœ¬æ”¶ç›Šåˆ†æ

### åœºæ™¯1: å¤„ç†500ä¸ªCæ–‡ä»¶

| é¡¹ç›® | å½“å‰ | +Cache | +Batch API | èŠ‚çœ |
|------|------|--------|------------|------|
| System message | $0.75 | $0.075 | $0.038 | 95% |
| User prompt | $59.25 | $59.25 | $29.63 | 50% |
| **æ€»è®¡** | **$60** | **$59.33** | **$29.67** | **51%** |

### åœºæ™¯2: å¤„ç†10,000ä¸ªæ–‡ä»¶

| é¡¹ç›® | å½“å‰ | +Cache | +Batch API | èŠ‚çœ |
|------|------|--------|------------|------|
| System message | $15 | $1.5 | $0.75 | 95% |
| User prompt | $1,185 | $1,185 | $592.5 | 50% |
| **æ€»è®¡** | **$1,200** | **$1,186.5** | **$593.25** | **51%** |

**æ€»èŠ‚çœ**: **Prompt Cache (90%) + Batch API (50%) = ~51%ç»¼åˆèŠ‚çœ**

---

## ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¯åš

1. âœ… **éªŒè¯Batch APIæ”¯æŒ**
   ```bash
   cd /home/changdi/sactor
   python3 test_batch_api.py
   ```

2. âœ… **åˆ›å»ºBatch APIå°è£…**
   - å®ç°è¯·æ±‚æ”¶é›†
   - å®ç°JSONLç”Ÿæˆ
   - å®ç°ç»“æœè§£æ

3. âœ… **å°è§„æ¨¡æµ‹è¯•**
   - 10ä¸ªæ–‡ä»¶
   - éªŒè¯æ­£ç¡®æ€§
   - å¯¹æ¯”æˆæœ¬

### åç»­ä¼˜åŒ–

1. **æ™ºèƒ½è·¯ç”±**: æ ¹æ®ä»»åŠ¡é‡è‡ªåŠ¨é€‰æ‹©æ¨¡å¼
2. **å¹¶è¡Œå¤„ç†**: Batch API + å¤šçº¿ç¨‹ä¸Šä¼ 
3. **å¢é‡æ›´æ–°**: åªç¿»è¯‘ä¿®æ”¹çš„æ–‡ä»¶

---

## æ€»ç»“

### æ¨èæ–¹æ¡ˆ

**æ··åˆæ–¹æ¡ˆ**: Prompt Cache + Batch API

1. **Prompt Cache** (å·²å®æ–½): èŠ‚çœ90% system messageæˆæœ¬
2. **Batch API** (å¾…å®æ–½): èŠ‚çœ50%æ€»ä½“æˆæœ¬

**ç»¼åˆä¼˜åŠ¿**:
- âœ… æœ€å¤§æˆæœ¬èŠ‚çœï¼ˆ~51%ï¼‰
- âœ… çµæ´»æ€§é«˜ï¼ˆå¯é€‰å®æ—¶æˆ–æ‰¹é‡ï¼‰
- âœ… å‘åå…¼å®¹

**ç¬¬ä¸€æ­¥**: éªŒè¯Qwenæ˜¯å¦æ”¯æŒBatch API
**ç¬¬äºŒæ­¥**: å®ç°Batch APIå°è£…
**ç¬¬ä¸‰æ­¥**: é›†æˆåˆ°ç°æœ‰æµç¨‹

---

## å‚è€ƒèµ„æº

- [OpenAI Batch APIæ–‡æ¡£](https://platform.openai.com/docs/guides/batch)
- [Alibaba Cloud Model Studio](https://help.aliyun.com/zh/model-studio/)
- å½“å‰å®ç°: `/home/changdi/sactor/sactor/llm/qwen_llm.py`

