#!/usr/bin/env python3
"""
ä½¿ç”¨ LLM ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œæ‰¹é‡ç¿»è¯‘
- åŸå§‹ç¨‹åº: /home/changdi/sactor-datasets/Project_CodeNet/raw_data/
- LLMç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹: /home/changdi/sactor/llm_generated_tests/
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
import argparse

class LLMTestTranslator:
    """ä½¿ç”¨ LLM ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œæ‰¹é‡ç¿»è¯‘"""
    
    def __init__(self, max_workers: int = 4, output_base_dir: str = None):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        self.temp_dir = tempfile.mkdtemp(prefix='sactor_llm_test_')
        self.max_workers = max_workers
        self.lock = threading.Lock()
        
        # æ•°æ®ç›®å½•
        self.codenet_data_dir = "/home/changdi/CodeNet/Project_CodeNet/data"
        
        # æŸ¥æ‰¾æœ€æ–°çš„æµ‹è¯•ç”Ÿæˆç›®å½•
        sactor_dir = "/home/changdi/sactor"
        test_gen_dirs = [d for d in os.listdir(sactor_dir) if d.startswith('test_generation_')]
        if test_gen_dirs:
            # é€‰æ‹©æœ€æ–°çš„
            test_gen_dirs.sort(reverse=True)
            self.llm_test_dir = os.path.join(sactor_dir, test_gen_dirs[0])
            print(f"ğŸ“ ä½¿ç”¨æµ‹è¯•ç›®å½•: {self.llm_test_dir}")
        else:
            # å›é€€åˆ°é»˜è®¤ç›®å½•
            self.llm_test_dir = "/home/changdi/sactor/llm_generated_tests"
            print(f"âš ï¸ æœªæ‰¾åˆ° test_generation_* ç›®å½•ï¼Œä½¿ç”¨é»˜è®¤: {self.llm_test_dir}")
        
        # ç»Ÿè®¡è®¡æ•°å™¨ï¼ˆç”¨äºè®¡ç®—å‡†ç¡®ç‡ï¼‰
        self.success_count = 0
        self.total_count = 0
        
        # æ—¥å¿—æ–‡ä»¶è·¯å¾„
        if output_base_dir:
            log_dir = os.path.join(output_base_dir, "logs")
            os.makedirs(log_dir, exist_ok=True)
            self.csv_log_file = os.path.join(log_dir, f"translation_log.csv")
            # åˆ›å»º CSV è¡¨å¤´
            with open(self.csv_log_file, 'w') as f:
                f.write("timestamp,c_file,success,processing_time,test_count,verified,success_rate,error\n")
        else:
            self.csv_log_file = None
        
        print(f"ğŸ“ ä¸´æ—¶å·¥ä½œç›®å½•: {self.temp_dir}")
        print(f"ğŸ“ CodeNet æ•°æ®ç›®å½•: {self.codenet_data_dir}")
        print(f"ğŸ”§ å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°: {self.max_workers}")
        if self.csv_log_file:
            print(f"ğŸ“ CSV æ—¥å¿—æ–‡ä»¶: {self.csv_log_file}")
    
    def __del__(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def _get_model_info(self) -> str:
        """è·å–å½“å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯"""
        try:
            config_path = "/home/changdi/sactor/sactor.toml"
            if os.path.exists(config_path):
                with open(config_path, 'r') as f:
                    content = f.read()
                    import re
                    
                    # æŸ¥æ‰¾å½“å‰ä½¿ç”¨çš„LLM
                    llm_match = re.search(r'llm = "([^"]+)"', content)
                    if llm_match:
                        llm_type = llm_match.group(1)
                        
                        # æ ¹æ®LLMç±»å‹æŸ¥æ‰¾å¯¹åº”çš„modelé…ç½®
                        section_match = re.search(rf'\[{llm_type}\](.*?)(?=\[|$)', content, re.DOTALL)
                        if section_match:
                            model_match = re.search(r'model = "([^"]+)"', section_match.group(1))
                            if model_match:
                                return f"{llm_type}-{model_match.group(1)}"
                    
            return "Unknown"
        except Exception as e:
            print(f"âš ï¸ è·å–æ¨¡å‹ä¿¡æ¯å¤±è´¥: {e}")
            return "Unknown"
    
    def find_c_file_by_name(self, c_filename: str) -> Optional[str]:
        """æ ¹æ®æ–‡ä»¶ååœ¨ CodeNet ä¸­æŸ¥æ‰¾å¯¹åº”çš„ C æ–‡ä»¶"""
        # éå†æ‰€æœ‰é—®é¢˜ç›®å½•æŸ¥æ‰¾
        for item in os.listdir(self.codenet_data_dir):
            problem_dir = os.path.join(self.codenet_data_dir, item)
            if os.path.isdir(problem_dir) and item.startswith('p'):
                c_dir = os.path.join(problem_dir, 'C')
                c_file_path = os.path.join(c_dir, c_filename)
                if os.path.exists(c_file_path):
                    return c_file_path
        return None
    
    def collect_files_to_translate(self) -> List[tuple]:
        """æ”¶é›†æ‰€æœ‰æœ‰ LLM æµ‹è¯•çš„æ–‡ä»¶"""
        files_to_translate = []
        
        # éå† llm_generated_tests ç›®å½•ä¸­çš„æ‰€æœ‰æµ‹è¯•æ–‡ä»¶
        if not os.path.exists(self.llm_test_dir):
            print(f"âš ï¸ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {self.llm_test_dir}")
            return []
        
        for filename in os.listdir(self.llm_test_dir):
            if filename.endswith('_test_samples.json'):
                # æå– C æ–‡ä»¶å
                c_name = filename.replace('_test_samples.json', '')
                c_filename = c_name + '.c'
                
                # æŸ¥æ‰¾æµ‹è¯•ä»»åŠ¡æ–‡ä»¶
                test_samples_path = os.path.join(self.llm_test_dir, filename)
                test_task_path = os.path.join(self.llm_test_dir, f"{c_name}_test_task.json")
                
                if not os.path.exists(test_task_path):
                    continue
                
                # åœ¨ CodeNet ä¸­æŸ¥æ‰¾å¯¹åº”çš„ C æ–‡ä»¶
                c_file_path = self.find_c_file_by_name(c_filename)
                if c_file_path:
                    files_to_translate.append((c_file_path, test_samples_path, test_task_path))
        
        return files_to_translate
    
    def fix_test_task_paths(self, test_task_path: str, test_samples_path: str) -> str:
        """ä¿®æ­£ test_task.json ä¸­çš„è·¯å¾„ï¼Œè¿”å›ä¿®æ­£åçš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„"""
        with open(test_task_path, 'r') as f:
            test_tasks = json.load(f)
        
        # è·å–æ–‡ä»¶å
        test_samples_basename = os.path.basename(test_samples_path)
        
        # ä¿®æ­£æ¯ä¸ªå‘½ä»¤ä¸­çš„è·¯å¾„
        modified = False
        for task in test_tasks:
            if 'command' in task:
                cmd = task['command']
                # å°†ä»»ä½•ç»å¯¹è·¯å¾„æ›¿æ¢ä¸ºç›¸å¯¹è·¯å¾„
                # åŒ¹é… /app/output/xxx_test_samples.json æˆ–å…¶ä»–ç»å¯¹è·¯å¾„
                import re
                new_cmd = re.sub(r'/[^\s]+_test_samples\.json', f'./{test_samples_basename}', cmd)
                if cmd != new_cmd:
                    modified = True
                task['command'] = new_cmd
        
        if modified:
            print(f"   â„¹ï¸  ä¿®æ­£äº† test_task.json ä¸­çš„è·¯å¾„: /app/output/... â†’ ./{test_samples_basename}")
        
        # ä¿å­˜åˆ°ä¸´æ—¶ç›®å½•
        import tempfile
        temp_file = os.path.join(tempfile.gettempdir(), f'fixed_{os.path.basename(test_task_path)}')
        with open(temp_file, 'w') as f:
            json.dump(test_tasks, f, indent=2)
        
        return temp_file
    
    def translate_single_file(self, c_file_path: str, test_samples_path: str, test_task_path: str, output_base_dir: str) -> Dict:
        """ç¿»è¯‘å•ä¸ªCæ–‡ä»¶"""
        start_time = time.time()
        c_filename = os.path.basename(c_file_path)
        
        try:
            # æ‰“å°æ–‡ä»¶ä¿¡æ¯
            print(f"\nğŸ” å‡†å¤‡ç¿»è¯‘: {c_filename}")
            print(f"   C æ–‡ä»¶è·¯å¾„: {c_file_path}")
            print(f"   æµ‹è¯•æ ·æœ¬: {test_samples_path}")
            print(f"   æµ‹è¯•ä»»åŠ¡: {test_task_path}")
            
            # è‡ªåŠ¨ä¿®æ­£ test_task.json ä¸­çš„è·¯å¾„
            fixed_test_task_path = self.fix_test_task_paths(test_task_path, test_samples_path)
            print(f"   ä¿®æ­£åçš„æµ‹è¯•ä»»åŠ¡: {fixed_test_task_path}")
            
            # è¯»å–æµ‹è¯•ç”¨ä¾‹æ•°é‡
            with open(test_samples_path, 'r') as f:
                test_samples = json.load(f)
            test_count = len(test_samples)
            print(f"   æµ‹è¯•ç”¨ä¾‹æ•°: {test_count}")
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            c_name = c_filename.replace('.c', '')
            file_output_dir = os.path.join(output_base_dir, c_name)
            os.makedirs(file_output_dir, exist_ok=True)
            
            # æ„å»ºDockerå‘½ä»¤ - éœ€è¦åŒæ—¶æŒ‚è½½ C æ–‡ä»¶ã€æµ‹è¯•ç›®å½•å’Œç»“æœç›®å½•
            sactor_config = "/home/changdi/sactor/sactor.toml"
            fixed_test_task_dir = os.path.dirname(fixed_test_task_path)
            
            cmd = [
                "docker", "run", "--rm",
                "-v", f"{sactor_config}:/app/sactor.toml",
                "-v", f"{c_file_path}:/tmp/test_c/{c_filename}",  # æŒ‚è½½å•ä¸ª C æ–‡ä»¶
                "-v", f"{test_samples_path}:/tmp/test_task/{os.path.basename(test_samples_path)}",  # æŒ‚è½½ test_samples
                "-v", f"{fixed_test_task_path}:/tmp/test_task/{os.path.basename(fixed_test_task_path)}",  # æŒ‚è½½ä¿®æ­£åçš„ test_task
                "-v", f"{file_output_dir}:/tmp/result",
                "sactor", "translate",
                f"/tmp/test_c/{c_filename}",
                f"/tmp/test_task/{os.path.basename(fixed_test_task_path)}",
                "--result-dir", "/tmp/result",
                "--type", "bin"
            ]
            
            print(f"   Docker å‘½ä»¤: {' '.join(cmd)}")
            print(f"\nâ–¶ï¸  å¼€å§‹ç¿»è¯‘...\n")
            print("=" * 80)
            
            # è¿è¡Œç¿»è¯‘ (2åˆ†é’Ÿè¶…æ—¶) - ä¸æ•è·è¾“å‡ºï¼Œç›´æ¥å®æ—¶æ˜¾ç¤º
            result = subprocess.run(cmd, timeout=600)
            
            processing_time = time.time() - start_time
            print("=" * 80)
            print(f"\nâ±ï¸  ç¿»è¯‘è€—æ—¶: {processing_time:.2f} ç§’")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(fixed_test_task_path):
                os.remove(fixed_test_task_path)
            
            if result.returncode == 0:
                # æ£€æŸ¥ç¿»è¯‘ç»“æœ - ç›´æ¥åœ¨ file_output_dir ä¸­
                unidiomatic_dir = os.path.join(file_output_dir, "translated_code_unidiomatic")
                idiomatic_dir = os.path.join(file_output_dir, "translated_code_idiomatic")
                
                verification = {
                    'unidiomatic': os.path.exists(unidiomatic_dir),
                    'idiomatic': os.path.exists(idiomatic_dir),
                    'overall': os.path.exists(unidiomatic_dir) and os.path.exists(idiomatic_dir)
                }
                
                return {
                    'success': True,
                    'c_file': c_filename,
                    'processing_time': processing_time,
                    'attempts': 1,  # Dockerè¾“å‡ºä¸­ä¸åŒ…å«å°è¯•æ¬¡æ•°
                    'api_cost': {},
                    'test_count': test_count,
                    'verification': verification,
                    'error': None
                }
            else:
                return {
                    'success': False,
                    'c_file': c_filename,
                    'error': f"Translation failed with return code: {result.returncode}",
                    'processing_time': processing_time,
                    'attempts': 0,
                    'api_cost': {},
                    'test_count': test_count,
                    'verification': None
                }
                
        except subprocess.TimeoutExpired as e:
            print(f"\nâ±ï¸  è¶…æ—¶ï¼ç¿»è¯‘æ—¶é—´è¶…è¿‡ 2 åˆ†é’Ÿ")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'fixed_test_task_path' in locals() and os.path.exists(fixed_test_task_path):
                os.remove(fixed_test_task_path)
            return {
                'success': False,
                'c_file': c_filename,
                'error': "Translation timeout (5 minutes)",
                'processing_time': 600,
                'attempts': 0,
                'api_cost': {},
                'test_count': 0,
                'verification': None
            }
        except Exception as e:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if 'fixed_test_task_path' in locals() and os.path.exists(fixed_test_task_path):
                os.remove(fixed_test_task_path)
            return {
                'success': False,
                'c_file': c_filename,
                'error': f"Exception: {str(e)}",
                'processing_time': time.time() - start_time,
                'attempts': 0,
                'api_cost': {},
                'test_count': 0,
                'verification': None
            }
    
    def batch_translate(self, output_base_dir: str, max_files: int = None) -> Dict:
        """æ‰¹é‡ç¿»è¯‘ - å¹¶è¡Œç‰ˆæœ¬"""
        # æ”¶é›†æ‰€æœ‰æœ‰LLMæµ‹è¯•çš„æ–‡ä»¶
        print(f"ğŸ” æ­£åœ¨æ‰«æ LLM ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹...")
        all_files_to_translate = self.collect_files_to_translate()
        
        print(f"ğŸ“Š æ‰¾åˆ° {len(all_files_to_translate)} ä¸ªæœ‰LLMæµ‹è¯•ç”¨ä¾‹çš„Cæ–‡ä»¶")
        
        # é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡
        if max_files is not None and len(all_files_to_translate) > max_files:
            all_files_to_translate = all_files_to_translate[:max_files]
            print(f"âš ï¸ é™åˆ¶å¤„ç†å‰ {max_files} ä¸ªæ–‡ä»¶")
        
        results = {
            'total': len(all_files_to_translate),
            'success': 0,
            'failed': 0,
            'verified': 0,
            'total_processing_time': 0,
            'total_attempts': 0,
            'total_api_cost': 0,
            'details': [],
            'start_time': time.time()
        }
        
        processed_count = 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.translate_single_file, c_file, test_samples, test_task, output_base_dir): c_file 
                for c_file, test_samples, test_task in all_files_to_translate
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_file):
                c_file_path = future_to_file[future]
                processed_count += 1
                
                try:
                    result = future.result()
                    
                    # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœ
                    with self.lock:
                        if result['success']:
                            results['success'] += 1
                            if result.get('verification', {}).get('overall'):
                                results['verified'] += 1
                        else:
                            results['failed'] += 1
                        
                        results['total_processing_time'] += result['processing_time']
                        results['total_attempts'] += result.get('attempts', 0)
                        results['details'].append(result)
                        
                        # å®æ—¶ä¿å­˜åˆ° CSV
                        self._log_result_to_csv(result)
                        
                        # è®¡ç®—å½“å‰æˆåŠŸç‡
                        success_rate = (results['success'] / processed_count * 100)
                        
                        if result['success']:
                            print(f"\nâœ… ===== [{processed_count}/{len(all_files_to_translate)}] {result['c_file']}: ç¿»è¯‘æˆåŠŸ ({result['test_count']} ä¸ªæµ‹è¯•) | æˆåŠŸç‡: {success_rate:.1f}% =====\n")
                        else:
                            error_msg = result.get('error', 'Unknown error')
                            print(f"\nâŒ ===== [{processed_count}/{len(all_files_to_translate)}] {result['c_file']}: å¤±è´¥ | æˆåŠŸç‡: {success_rate:.1f}% =====")
                            print(f"   é”™è¯¯: {error_msg}\n")
                        
                        # æ¯å¤„ç†5ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡è¿›åº¦
                        if processed_count % 5 == 0:
                            self._save_progress(results, output_base_dir, processed_count)
                            
                except Exception as e:
                    with self.lock:
                        results['failed'] += 1
                        success_rate = (results['success'] / processed_count * 100)
                        print(f"\nâŒ [{processed_count}/{len(all_files_to_translate)}] {os.path.basename(c_file_path)}: å¼‚å¸¸ | æˆåŠŸç‡: {success_rate:.1f}%")
                        print(f"   ğŸ’¥ Exceptionè¯¦æƒ…:\n{str(e)}")
                        import traceback
                        print(f"   å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}")
                        
                        error_result = {
                            'success': False,
                            'c_file': os.path.basename(c_file_path),
                            'error': f"Exception in worker: {str(e)}",
                            'processing_time': 0,
                            'attempts': 0,
                            'api_cost': {},
                            'test_count': 0,
                            'verification': None
                        }
                        results['details'].append(error_result)
                        
                        # ä¿å­˜åˆ° CSV
                        self._log_result_to_csv(error_result)
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        
        # è®¡ç®—å¹³å‡å€¼
        if results['total'] > 0:
            results['avg_processing_time'] = results['total_processing_time'] / results['total']
            results['avg_attempts'] = results['total_attempts'] / results['total'] if results['total_attempts'] > 0 else 0
        
        return results
    
    def _log_result_to_csv(self, result: Dict):
        """å°†å•ä¸ªç»“æœå®æ—¶ä¿å­˜åˆ° CSVï¼ˆåŒ…å«å‡†ç¡®ç‡ï¼‰"""
        if not self.csv_log_file:
            return
        
        try:
            with self.lock:
                # æ›´æ–°è®¡æ•°å™¨
                self.total_count += 1
                if result.get('success', False):
                    self.success_count += 1
                
                # è®¡ç®—å½“å‰å‡†ç¡®ç‡
                success_rate = (self.success_count / self.total_count * 100) if self.total_count > 0 else 0
                
                timestamp = datetime.now().isoformat()
                c_file = result.get('c_file', 'unknown')
                success = result.get('success', False)
                processing_time = result.get('processing_time', 0)
                test_count = result.get('test_count', 0)
                verified = result.get('verification', {}).get('overall', False) if result.get('verification') else False
                error = str(result.get('error', '')).replace(',', ';').replace('\n', ' ')[:200]
                
                csv_line = f"{timestamp},{c_file},{success},{processing_time:.2f},{test_count},{verified},{success_rate:.2f},{error}\n"
                
                with open(self.csv_log_file, 'a') as f:
                    f.write(csv_line)
                    f.flush()  # å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜
                
                # è°ƒè¯•ä¿¡æ¯
                print(f"   ğŸ“Š CSVå·²ä¿å­˜: {c_file} | å‡†ç¡®ç‡: {success_rate:.1f}%")
        except Exception as e:
            print(f"âš ï¸ CSV æ—¥å¿—ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _save_progress(self, results: Dict, output_base_dir: str, processed_count: int):
        """ä¿å­˜è¿›åº¦"""
        progress_file = os.path.join(output_base_dir, f"progress_{processed_count}.json")
        with open(progress_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {processed_count}/{results['total']} æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ä½¿ç”¨LLMç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œæ‰¹é‡ç¿»è¯‘ï¼ˆå¹¶è¡Œç‰ˆæœ¬ï¼‰')
    parser.add_argument('--max-files', type=int, default=None, help='æœ€å¤šå¤„ç†çš„æ–‡ä»¶æ•°é‡ï¼ˆé»˜è®¤ï¼šå…¨éƒ¨ï¼‰')
    parser.add_argument('--workers', type=int, default=4, help='å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š4ï¼‰')
    args = parser.parse_args()
    
    print("ğŸš€ SACToR æ‰¹é‡ç¿»è¯‘å™¨ (ä½¿ç”¨LLMç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹)")
    print("=" * 60)
    print(f"ğŸ”§ é…ç½®: ")
    print(f"   - å¹¶è¡Œçº¿ç¨‹æ•°: {args.workers}")
    print(f"   - æœ€å¤šå¤„ç†æ–‡ä»¶: {'æ‰€æœ‰' if args.max_files is None else args.max_files}")
    print("=" * 60)
    
    # å…ˆåˆ›å»ºä¸€ä¸ªä¸´æ—¶ç¿»è¯‘å™¨æ¥è·å–æ¨¡å‹åç§°
    temp_translator = LLMTestTranslator(max_workers=1)
    model_name = temp_translator._get_model_info().replace('-', '_').replace('.', '_')
    del temp_translator
    
    # åˆ›å»ºä»¥æ—¥æœŸå‘½åçš„è¾“å‡ºç›®å½•
    date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_base_dir = f"/home/changdi/sactor/test_translation_{model_name}_{date_str}"
    os.makedirs(output_base_dir, exist_ok=True)
    
    # åˆ›å»ºç¿»è¯‘å™¨ï¼ˆä¼ å…¥ output_base_dir ä»¥åˆå§‹åŒ–æ—¥å¿—ï¼‰
    translator = LLMTestTranslator(max_workers=args.workers, output_base_dir=output_base_dir)
    
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_base_dir}")
    print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {translator._get_model_info()}")
    
    try:
        # æ‰¹é‡ç¿»è¯‘
        results = translator.batch_translate(output_base_dir, max_files=args.max_files)
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š æ‰¹é‡ç¿»è¯‘ç»“æœ:")
        print(f"å¤„ç†æ–‡ä»¶æ•°: {results['total']}")
        print(f"ç¿»è¯‘æˆåŠŸ: {results['success']}")
        print(f"ç¿»è¯‘å¤±è´¥: {results['failed']}")
        print(f"éªŒè¯é€šè¿‡: {results['verified']}")
        print(f"æ€»å¤„ç†æ—¶é—´: {results['duration']:.2f} ç§’ ({results['duration']/60:.1f} åˆ†é’Ÿ)")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {results['avg_processing_time']:.2f} ç§’/æ–‡ä»¶")
        if results['total'] > 0:
            print(f"æˆåŠŸç‡: {results['success']/results['total']*100:.1f}%")
            print(f"éªŒè¯ç‡: {results['verified']/results['total']*100:.1f}%")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(output_base_dir, "translation_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°:")
        print(f"   JSON: {results_file}")
        print(f"   CSV:  {translator.csv_log_file}")
        
        return results
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if hasattr(translator, 'temp_dir') and os.path.exists(translator.temp_dir):
            shutil.rmtree(translator.temp_dir)

if __name__ == "__main__":
    main()

