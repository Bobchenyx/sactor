#!/bin/bash
# ç¿»è¯‘ test_4k_accept_34 (ç¬¬3-4æ‰¹) - ä½¿ç”¨å›ºå®šæ¨¡å‹ qwen3-coder-flash-2025-07-28
# ä¸ä¿®æ”¹åŸå§‹ sactor.toml

# å‚æ•°è®¾ç½®ï¼ˆå¯ä»¥é€šè¿‡å‘½ä»¤è¡Œä¿®æ”¹ï¼‰
WORKERS=${1:-10}        # å¹¶å‘æ•°ï¼Œé»˜è®¤10
NUM_TESTS=${2:-6}       # æµ‹è¯•ç”¨ä¾‹æ•°ï¼Œé»˜è®¤6

echo "================================================================================"
echo "ğŸš€ å¼€å§‹ç¿»è¯‘ test_4k_accept_34 (ç¬¬3-4æ‰¹) - å›ºå®šæ¨¡å‹"
echo "================================================================================"
echo ""
echo "ğŸ“ Cæ–‡ä»¶: /home/changdi/CodeNet/test_4k_accept_34"
echo "ğŸ“ JSON: /home/changdi/sactor/generated_tests"
echo "ğŸ“ è¾“å‡º: /home/changdi/sactor/translated_rust_4k_34"
echo ""
echo "âš™ï¸  é…ç½®:"
echo "   - æ¨¡å‹: qwen3-coder-flash-2025-07-28 (å›ºå®š)"
echo "   - å¹¶å‘æ•°: $WORKERS"
echo "   - æµ‹è¯•ç”¨ä¾‹æ•°: $NUM_TESTS"
echo "   - ä¸ä¿®æ”¹åŸå§‹ sactor.toml"
echo ""
echo "================================================================================"
echo ""

cd /home/changdi/sactor

# åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶ï¼ˆfor Dockerï¼‰
TEMP_TOML="/tmp/sactor_34_fixed.toml"
cp /home/changdi/sactor/sactor.toml "$TEMP_TOML"

# ä¿®æ”¹ä¸´æ—¶é…ç½®ï¼šè®¾ç½®å›ºå®šæ¨¡å‹
sed -i '/\[Qwen\]/,/^\[/ s/model = ".*"/model = "qwen3-coder-flash-2025-07-28"/' "$TEMP_TOML"

echo "âœ… åˆ›å»ºä¸´æ—¶é…ç½®: $TEMP_TOML"
echo "âœ… æ¨¡å‹è®¾ç½®ä¸º: qwen3-coder-flash-2025-07-28"
echo ""

# åˆ›å»ºè‡ªå®šä¹‰ç¿»è¯‘è„šæœ¬ï¼Œä½¿ç”¨ä¸´æ—¶é…ç½®æ–‡ä»¶
cat > /tmp/translate_34_runner.py << 'EOF'
#!/usr/bin/env python3
import os
import json
import subprocess
import shutil
import tempfile
import threading
import time
from concurrent.futures import ThreadPoolExecutor, as_completed


class Translator34Fixed:
    def __init__(self, num_tests=6):
        self.c_files_dir = "/home/changdi/CodeNet/test_4k_accept_34"
        self.json_dir = "/home/changdi/sactor/generated_tests"
        self.output_base_dir = "/home/changdi/sactor/translated_rust_4k_34"
        self.sactor_docker_image = "sactor"
        self.config_file = "/tmp/sactor_34_fixed.toml"  # ä½¿ç”¨ä¸´æ—¶é…ç½®
        self.print_lock = threading.Lock()
        self.num_tests = num_tests
        
        self.total_tasks = 0
        self.completed = 0
        self.failed = 0
        self.skipped = 0
    
    def collect_translation_tasks(self):
        """æ”¶é›†æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡"""
        tasks = []
        problem_dirs = sorted([d for d in os.listdir(self.c_files_dir) 
                              if os.path.isdir(os.path.join(self.c_files_dir, d)) 
                              and d.startswith('p')])
        
        for problem_id in problem_dirs:
            c_dir = os.path.join(self.c_files_dir, problem_id, 'C')
            if not os.path.exists(c_dir):
                continue
            
            json_problem_dir = os.path.join(self.json_dir, problem_id, 'C')
            json_file = None
            
            if os.path.exists(json_problem_dir):
                json_files = sorted([f for f in os.listdir(json_problem_dir) 
                                   if f.endswith('.json')])
                if json_files:
                    json_file = os.path.join(json_problem_dir, json_files[0])
            
            if not json_file:
                continue
            
            c_files = sorted([f for f in os.listdir(c_dir) if f.endswith('.c')])
            
            for c_filename in c_files:
                c_file = os.path.join(c_dir, c_filename)
                submission_id = c_filename.replace('.c', '')
                output_dir = os.path.join(self.output_base_dir, problem_id, 
                                         'Rust', submission_id, 
                                         'translated_code_unidiomatic')
                
                tasks.append({
                    'task_id': f"{problem_id}/{submission_id}",
                    'problem_id': problem_id,
                    'submission_id': submission_id,
                    'c_file': c_file,
                    'json_file': json_file,
                    'output_dir': os.path.dirname(output_dir)
                })
        
        return tasks
    
    def translate_single_task(self, task):
        """ç¿»è¯‘å•ä¸ªä»»åŠ¡"""
        task_id = task['task_id']
        c_file = task['c_file']
        json_file = task['json_file']
        output_dir = task['output_dir']
        
        combined_rust_file = os.path.join(output_dir, 'translated_code_unidiomatic', 'combined.rs')
        
        if os.path.exists(combined_rust_file) and os.path.getsize(combined_rust_file) > 100:
            with self.print_lock:
                self.skipped += 1
                progress = f"[{self.completed + self.failed + self.skipped}/{self.total_tasks}]"
                print(f"â­ï¸  {progress} {task_id} - å·²å­˜åœ¨ï¼Œè·³è¿‡", flush=True)
            return {'status': 'skipped', 'task_id': task_id}
        
        temp_dir = f"/tmp/sactor_translate_{task['submission_id']}"
        os.makedirs(temp_dir, exist_ok=True)
        
        try:
            with open(json_file, 'r') as f:
                test_samples = json.load(f)
            
            test_samples_limited = test_samples[:self.num_tests]
            
            test_samples_path = os.path.join(temp_dir, 'test_samples.json')
            with open(test_samples_path, 'w') as f:
                json.dump(test_samples_limited, f, indent=2)
            
            test_task = []
            for i in range(len(test_samples_limited)):
                test_task.append({
                    "command": f"sactor run-tests --type bin ./test_samples.json %t {i} --feed-as-stdin",
                    "test_id": i
                })
            
            test_task_path = os.path.join(temp_dir, 'test_task.json')
            with open(test_task_path, 'w') as f:
                json.dump(test_task, f, indent=2)
            
            c_dir = os.path.dirname(c_file)
            c_filename = os.path.basename(c_file)
            os.makedirs(output_dir, exist_ok=True)
            
            docker_cmd = [
                "docker", "run", "--rm",
                "-v", f"{c_dir}:/input:ro",
                "-v", f"{temp_dir}:/work:ro",
                "-v", f"{output_dir}:/output",
                "-v", f"{self.config_file}:/app/sactor.toml:ro",  # ä½¿ç”¨ä¸´æ—¶é…ç½®
                "-w", "/work",
                self.sactor_docker_image,
                "translate",
                "--type", "bin",
                "--unidiomatic-only",
                "--result-dir", "/output",
                f"/input/{c_filename}",
                "/work/test_task.json"
            ]
            
            with self.print_lock:
                print(f"\n{'='*60}")
                print(f"ğŸ”„ ç¿»è¯‘: {task_id}")
                print(f"{'='*60}\n")
            
            process = subprocess.Popen(
                docker_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            output_lines = []
            for line in process.stdout:
                with self.print_lock:
                    print(line, end='', flush=True)
                output_lines.append(line)
            
            process.wait()
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            if os.path.exists(combined_rust_file) and os.path.getsize(combined_rust_file) > 100:
                with self.print_lock:
                    self.completed += 1
                    progress = f"[{self.completed + self.failed}/{self.total_tasks}]"
                    print(f"\nâœ… {progress} {task_id} - æˆåŠŸ\n")
                return {'status': 'success', 'task_id': task_id}
            else:
                with self.print_lock:
                    self.failed += 1
                    progress = f"[{self.completed + self.failed}/{self.total_tasks}]"
                    print(f"\nâŒ {progress} {task_id} - å¤±è´¥\n")
                return {'status': 'failed', 'task_id': task_id}
                
        except Exception as e:
            shutil.rmtree(temp_dir, ignore_errors=True)
            with self.print_lock:
                self.failed += 1
                print(f"âŒ {task_id}: {str(e)}")
            return {'status': 'error', 'task_id': task_id, 'error': str(e)}
    
    def run(self, workers=10):
        """æ‰§è¡Œæ‰¹é‡ç¿»è¯‘"""
        tasks = self.collect_translation_tasks()
        if not tasks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¿»è¯‘ä»»åŠ¡")
            return
        
        self.total_tasks = len(tasks)
        print(f"\nğŸ”„ å¼€å§‹ç¿»è¯‘ {self.total_tasks} ä¸ªä»»åŠ¡...\n")
        
        os.makedirs(self.output_base_dir, exist_ok=True)
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = {executor.submit(self.translate_single_task, task): task 
                      for task in tasks}
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                except Exception as e:
                    with self.print_lock:
                        self.failed += 1
                        print(f"âŒ ä»»åŠ¡å¼‚å¸¸: {str(e)}")
        
        elapsed = time.time() - start_time
        
        print("\n" + "=" * 80)
        print("ğŸ“Š ç¿»è¯‘å®Œæˆ")
        print("=" * 80)
        print(f"âœ… æˆåŠŸ: {self.completed}")
        print(f"â­ï¸  è·³è¿‡: {self.skipped}")
        print(f"âŒ å¤±è´¥: {self.failed}")
        print(f"ğŸ“ æ€»æ•°: {self.total_tasks}")
        print(f"â±ï¸  ç”¨æ—¶: {elapsed:.1f} ç§’")
        print("=" * 80)


if __name__ == "__main__":
    import sys
    workers = int(sys.argv[1]) if len(sys.argv) > 1 else 10
    num_tests = int(sys.argv[2]) if len(sys.argv) > 2 else 6
    
    translator = Translator34Fixed(num_tests=num_tests)
    translator.run(workers=workers)
EOF

chmod +x /tmp/translate_34_runner.py

# è¿è¡Œç¿»è¯‘ï¼Œä¼ é€’å‚æ•°
python3 -u /tmp/translate_34_runner.py "$WORKERS" "$NUM_TESTS"

EXIT_CODE=$?

# æ¸…ç†ä¸´æ—¶æ–‡ä»¶
rm -f "$TEMP_TOML"
rm -f /tmp/translate_34_runner.py

echo ""
echo "âœ… ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†"
echo "================================================================================"

exit $EXIT_CODE
