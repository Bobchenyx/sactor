# SACToR å®Œæ•´ç¿»è¯‘æµç¨‹è¯¦è§£

## ğŸ”„ **æ•´ä½“æµç¨‹æ¦‚è§ˆ**

```
è¾“å…¥ C æ–‡ä»¶ â†’ é¢„å¤„ç† â†’ éæƒ¯ç”¨ç¿»è¯‘ â†’ ç»„åˆ â†’ æƒ¯ç”¨ç¿»è¯‘ â†’ éªŒè¯ â†’ è¾“å‡º Rust ä»£ç 
```

## ğŸ“¥ **1. è¾“å…¥é˜¶æ®µ**

### **è¾“å…¥æ–‡ä»¶**
- **C æºæ–‡ä»¶**: `/home/changdi/sactor-datasets/Project_CodeNet/selected_data_raw/argv/s005765690.c`
- **æµ‹è¯•é…ç½®**: `test_task.json` + `test_samples.json`

### **ç¤ºä¾‹ C æ–‡ä»¶**
```c
#include<stdio.h>
#include<stdlib.h>

int main(int argc, char* argv[]){
    int n = atoi(argv[1]);
    int i = 0;
    double s = 0;
    for(i = 0; i < n; i++){
        if(i%3 != 0 && i%5 != 0)
            s += i;
    }
    printf("%lf\n", s);
    return 0;
}
```

## ğŸ”§ **2. é¢„å¤„ç†é˜¶æ®µ**

### **åŠ¨æ€ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹**
```python
def generate_correct_test_samples(c_file_path):
    # 1. ç¼–è¯‘ C ç¨‹åº
    gcc s005765690.c -o test_binary
    
    # 2. è¿è¡Œè·å–æœŸæœ›è¾“å‡º
    ./test_binary 10  # è¾“å‡º: 22.000000
    ./test_binary 5   # è¾“å‡º: 7.000000
    ./test_binary 0   # è¾“å‡º: 0.000000
    
    # 3. ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    test_samples = [
        {"input": "10", "output": "22.000000"},
        {"input": "5", "output": "7.000000"},
        {"input": "0", "output": "0.000000"}
    ]
```

### **ç”Ÿæˆæµ‹è¯•ä»»åŠ¡æ–‡ä»¶**
```json
// test_task.json
[
    {"command": "sactor run-tests --type bin ./test_samples.json %t 0 --feed-as-args", "test_id": 0},
    {"command": "sactor run-tests --type bin ./test_samples.json %t 1 --feed-as-args", "test_id": 1},
    {"command": "sactor run-tests --type bin ./test_samples.json %t 2 --feed-as-args", "test_id": 2}
]
```

## ğŸ¤– **3. SACToR Docker è°ƒç”¨**

### **Docker å‘½ä»¤**
```bash
docker run --rm \
  -v /home/changdi/sactor/sactor.toml:/app/sactor.toml \
  -v /tmp/translation:/tmp/translation \
  sactor translate \
  /tmp/translation/s005765690.c \
  /tmp/translation/test_task.json \
  --result-dir /tmp/translation/result \
  --type bin
```

### **SACToR å†…éƒ¨æµç¨‹**
```python
# sactor/sactor.py
def run(self):
    # 1. éæƒ¯ç”¨ä»£ç ç¿»è¯‘
    result, unidiomatic_translator = self._run_unidomatic_translation()
    
    # 2. ç»„åˆéæƒ¯ç”¨ä»£ç 
    combine_result, _ = self.combiner.combine(
        "translated_code_unidiomatic", is_idiomatic=False
    )
    
    # 3. æƒ¯ç”¨ä»£ç ç¿»è¯‘
    result, idiomatic_translator = self._run_idiomatic_translation()
    
    # 4. ç»„åˆæƒ¯ç”¨ä»£ç 
    combine_result, _ = self.combiner.combine(
        "translated_code_idiomatic", is_idiomatic=True
    )
```

## ğŸ”„ **4. ç¿»è¯‘é˜¶æ®µ**

### **4.1 éæƒ¯ç”¨ç¿»è¯‘**
**ç›®æ ‡**: ç›´æ¥ç¿»è¯‘ C ä»£ç ï¼Œä¿æŒç›¸ä¼¼ç»“æ„

**è¿‡ç¨‹**:
1. **C2Rust è½¬æ¢**: ä½¿ç”¨ C2Rust å·¥å…·è¿›è¡Œåˆæ­¥è½¬æ¢
2. **LLM ä¼˜åŒ–**: ä½¿ç”¨ LLM ä¿®å¤ç¼–è¯‘é”™è¯¯å’Œç±»å‹é—®é¢˜
3. **éªŒè¯**: ç¼–è¯‘éªŒè¯ + åŠŸèƒ½æµ‹è¯•éªŒè¯

**è¾“å‡º**:
```rust
// translated_code_unidiomatic/combined.rs
pub fn main() -> () {
    use std::env;
    use std::ffi::CString;
    use libc::atoi;
    
    let args: Vec<String> = env::args().collect();
    let c_arg = CString::new(args[1].clone()).expect("CString::new failed");
    let n = unsafe { atoi(c_arg.as_ptr()) };
    
    let mut s: f64 = 0.0;
    for i in 0..n {
        if i % 3 != 0 && i % 5 != 0 {
            s += i as f64;
        }
    }
    println!("{:.6}", s);
}
```

### **4.2 æƒ¯ç”¨ç¿»è¯‘**
**ç›®æ ‡**: è½¬æ¢ä¸ºç¬¦åˆ Rust ä¹ æƒ¯çš„ä»£ç ï¼Œç§»é™¤ unsafe

**è¿‡ç¨‹**:
1. **LLM é‡æ„**: ä½¿ç”¨ LLM å°†éæƒ¯ç”¨ä»£ç è½¬æ¢ä¸ºæƒ¯ç”¨ä»£ç 
2. **å®‰å…¨åŒ–**: ç§»é™¤ unsafe å—ï¼Œä½¿ç”¨ Rust åŸç”Ÿæ–¹æ³•
3. **éªŒè¯**: ç¼–è¯‘éªŒè¯ + åŠŸèƒ½æµ‹è¯•éªŒè¯

**è¾“å‡º**:
```rust
// translated_code_idiomatic/combined.rs
pub fn main() {
    use std::env;
    
    let args: Vec<String> = env::args().collect();
    let n: i32 = match args[1].parse() {
        Ok(num) => num,
        Err(_) => {
            eprintln!("Error: Please provide a valid integer.");
            return;
        }
    };
    
    if n <= 0 {
        println!("{:.6}", 0.0);
        return;
    }
    
    let s: f64 = (0..n)
        .filter(|&i| i % 3 != 0 && i % 5 != 0)
        .map(|i| i as f64)
        .sum();
    
    println!("{:.6}", s);
}
```

## ğŸ§ª **5. éªŒè¯é˜¶æ®µ**

### **5.1 ç¼–è¯‘éªŒè¯**
```bash
# ç¼–è¯‘ Rust ä»£ç 
cargo build --manifest-path Cargo.toml

# æ£€æŸ¥ç¼–è¯‘ç»“æœ
if cargo build succeeds:
    compilation_result = SUCCESS
else:
    compilation_result = FAILED
```

### **5.2 åŠŸèƒ½éªŒè¯**
```bash
# è¿è¡Œæµ‹è¯•ç”¨ä¾‹
sactor run-tests --type bin ./test_samples.json target_binary 0 --feed-as-args
sactor run-tests --type bin ./test_samples.json target_binary 1 --feed-as-args
sactor run-tests --type bin ./test_samples.json target_binary 2 --feed-as-args

# æ¯”è¾ƒè¾“å‡º
actual_output = "22.000000"
expected_output = "22.000000"
if actual_output == expected_output:
    test_result = PASSED
else:
    test_result = FAILED
```

### **5.3 å†…å­˜éªŒè¯ (Valgrind)**
```bash
# ä½¿ç”¨ Valgrind æ£€æŸ¥å†…å­˜æ³„æ¼
valgrind --tool=memcheck --leak-check=full target_binary 10

# æ£€æŸ¥ç»“æœ
if no memory leaks:
    memory_result = CLEAN
else:
    memory_result = LEAKS_DETECTED
```

### **5.4 é™æ€åˆ†æ (Clippy)**
```bash
# è¿è¡Œ Rust Clippy é™æ€åˆ†æ
cargo clippy --manifest-path Cargo.toml

# æ£€æŸ¥è­¦å‘Šå’Œé”™è¯¯
if no warnings:
    clippy_result = CLEAN
else:
    clippy_result = WARNINGS_FOUND
```

## ğŸ“Š **6. éªŒè¯ç»“æœæ±‡æ€»**

### **éªŒè¯æ ‡å‡†**
```python
verification_results = {
    'unidiomatic': {
        'compilation': True/False,
        'functionality': True/False,
        'memory': True/False,
        'clippy': True/False
    },
    'idiomatic': {
        'compilation': True/False,
        'functionality': True/False,
        'memory': True/False,
        'clippy': True/False
    },
    'overall': True/False  # æ‰€æœ‰éªŒè¯éƒ½é€šè¿‡
}
```

### **æˆåŠŸæ ‡å‡†**
- âœ… **ç¼–è¯‘æˆåŠŸ**: Rust ä»£ç èƒ½å¤ŸæˆåŠŸç¼–è¯‘
- âœ… **åŠŸèƒ½æ­£ç¡®**: æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹éƒ½é€šè¿‡
- âœ… **å†…å­˜å®‰å…¨**: Valgrind æ£€æŸ¥æ— å†…å­˜æ³„æ¼
- âœ… **ä»£ç è´¨é‡**: Clippy æ£€æŸ¥æ— è­¦å‘Š

## ğŸ“ **7. è¾“å‡ºé˜¶æ®µ**

### **è¾“å‡ºæ–‡ä»¶ç»“æ„**
```
/tmp/translation/result/
â”œâ”€â”€ translated_code_unidiomatic/
â”‚   â”œâ”€â”€ combined.rs          # éæƒ¯ç”¨ Rust ä»£ç 
â”‚   â”œâ”€â”€ Cargo.toml           # é¡¹ç›®é…ç½®
â”‚   â””â”€â”€ target/              # ç¼–è¯‘è¾“å‡º
â”œâ”€â”€ translated_code_idiomatic/
â”‚   â”œâ”€â”€ combined.rs          # æƒ¯ç”¨ Rust ä»£ç 
â”‚   â”œâ”€â”€ Cargo.toml           # é¡¹ç›®é…ç½®
â”‚   â””â”€â”€ target/              # ç¼–è¯‘è¾“å‡º
â”œâ”€â”€ unidiomatic_failure_info.json  # éæƒ¯ç”¨ç¿»è¯‘å¤±è´¥ä¿¡æ¯
â”œâ”€â”€ idiomatic_failure_info.json    # æƒ¯ç”¨ç¿»è¯‘å¤±è´¥ä¿¡æ¯
â””â”€â”€ llm_stat.json                   # LLM ä½¿ç”¨ç»Ÿè®¡
```

### **æœ€ç»ˆç»“æœ**
```json
{
    "success": true,
    "verification": {
        "unidiomatic": {"success": true, "details": {...}},
        "idiomatic": {"success": true, "details": {...}},
        "overall": true
    },
    "test_count": 3,
    "result_dir": "/tmp/translation/result"
}
```

## ğŸ”„ **8. å®Œæ•´æµç¨‹å›¾**

```mermaid
graph TD
    A[C æºæ–‡ä»¶] --> B[ç¼–è¯‘ C ç¨‹åº]
    B --> C[ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹]
    C --> D[åˆ›å»ºæµ‹è¯•é…ç½®]
    D --> E[SACToR Docker è°ƒç”¨]
    E --> F[C2Rust è½¬æ¢]
    F --> G[LLM éæƒ¯ç”¨ç¿»è¯‘]
    G --> H[ç¼–è¯‘éªŒè¯]
    H --> I[åŠŸèƒ½æµ‹è¯•éªŒè¯]
    I --> J[Valgrind å†…å­˜æ£€æŸ¥]
    J --> K[ç»„åˆéæƒ¯ç”¨ä»£ç ]
    K --> L[LLM æƒ¯ç”¨ç¿»è¯‘]
    L --> M[ç¼–è¯‘éªŒè¯]
    M --> N[åŠŸèƒ½æµ‹è¯•éªŒè¯]
    N --> O[Valgrind å†…å­˜æ£€æŸ¥]
    O --> P[Clippy é™æ€åˆ†æ]
    P --> Q[ç»„åˆæƒ¯ç”¨ä»£ç ]
    Q --> R[è¾“å‡º Rust ä»£ç ]
```

## ğŸ¯ **å…³é”®ç‰¹ç‚¹**

1. **åŒé‡ç¿»è¯‘**: éæƒ¯ç”¨ â†’ æƒ¯ç”¨ï¼Œç¡®ä¿ä»£ç è´¨é‡
2. **å¤šå±‚éªŒè¯**: ç¼–è¯‘ + åŠŸèƒ½ + å†…å­˜ + é™æ€åˆ†æ
3. **åŠ¨æ€æµ‹è¯•**: è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿å‡†ç¡®æ€§
4. **å®Œæ•´æµç¨‹**: ä» C åˆ° Rust çš„ç«¯åˆ°ç«¯è½¬æ¢
5. **è´¨é‡ä¿è¯**: å¤šé‡éªŒè¯ç¡®ä¿ç¿»è¯‘è´¨é‡
