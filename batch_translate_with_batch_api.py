#!/usr/bin/env python3
"""
ä½¿ç”¨Batch APIä¼˜åŒ–çš„æ‰¹é‡ç¿»è¯‘è„šæœ¬

ç­–ç•¥ï¼š
1. æ”¶é›†æ‰€æœ‰Cæ–‡ä»¶çš„æµ‹è¯•ç”Ÿæˆè¯·æ±‚
2. ä½¿ç”¨Batch APIä¸€æ¬¡æ€§æäº¤
3. ç­‰å¾…ç»“æœï¼ˆ50%æˆæœ¬æŠ˜æ‰£ï¼‰
4. è§£æç»“æœå¹¶ä¿å­˜

é€‚ç”¨åœºæ™¯ï¼šå¤§æ‰¹é‡ç¿»è¯‘ï¼ˆ>50ä¸ªæ–‡ä»¶ï¼‰ï¼Œå¯ä»¥ç­‰å¾…
"""

import os
import json
import time
from datetime import datetime
from openai import OpenAI
from pathlib import Path

class BatchAPITranslator:
    def __init__(self):
        """åˆå§‹åŒ–Batch APIç¿»è¯‘å™¨"""
        self.client = OpenAI(
            api_key="sk-aaca0ccf722143a39ec3c6e38a0a4bc2",
            base_url="https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
        )
        
        self.raw_data_dir = "/home/changdi/CodeNet/new-data"
        self.output_dir = f"/home/changdi/sactor/batch_api_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print("="*80)
        print("ğŸš€ Batch API æ‰¹é‡ç¿»è¯‘å™¨")
        print("="*80)
        print(f"ğŸ“ æ•°æ®æº: {self.raw_data_dir}")
        print(f"ğŸ“ è¾“å‡º: {self.output_dir}")
        print("="*80)
    
    def collect_c_files(self, sample_size=100):
        """æ”¶é›†Cæ–‡ä»¶"""
        print(f"\nğŸ” æ”¶é›†Cæ–‡ä»¶ (æœ€å¤š {sample_size} ä¸ª)...")
        
        all_c_files = []
        problem_dirs = sorted([d for d in os.listdir(self.raw_data_dir) 
                              if d.startswith('p') and os.path.isdir(os.path.join(self.raw_data_dir, d))])
        
        import random
        random.shuffle(problem_dirs)
        
        for problem_dir in problem_dirs[:sample_size]:
            c_dir = os.path.join(self.raw_data_dir, problem_dir, 'C')
            if os.path.exists(c_dir):
                c_files = [os.path.join(c_dir, f) for f in os.listdir(c_dir) if f.endswith('.c')]
                if c_files:
                    all_c_files.append(random.choice(c_files))
            
            if len(all_c_files) >= sample_size:
                break
        
        print(f"âœ… æ”¶é›†åˆ° {len(all_c_files)} ä¸ªCæ–‡ä»¶")
        return all_c_files
    
    def create_batch_requests(self, c_files, num_tests=8):
        """åˆ›å»ºbatchè¯·æ±‚"""
        print(f"\nğŸ“ åˆ›å»ºBatch APIè¯·æ±‚...")
        
        requests = []
        file_mapping = {}  # custom_id -> c_file_path
        
        for idx, c_file_path in enumerate(c_files):
            try:
                # è¯»å–Cä»£ç 
                with open(c_file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    c_code = f.read()
                
                # é™åˆ¶ä»£ç é•¿åº¦
                if len(c_code) > 10000:
                    c_code = c_code[:10000]
                
                custom_id = f"test-gen-{idx}"
                file_mapping[custom_id] = c_file_path
                
                # åˆ›å»ºæµ‹è¯•ç”Ÿæˆè¯·æ±‚
                request = {
                    "custom_id": custom_id,
                    "method": "POST",
                    "url": "/v1/chat/completions",
                    "body": {
                        "model": "qwen3-coder-plus",
                        "messages": [
                            {
                                "role": "system",
                                "content": "You are an expert in generating test cases for C programs. Generate diverse test inputs that cover edge cases, typical cases, and boundary conditions.",
                                "cache_control": {"type": "ephemeral"}
                            },
                            {
                                "role": "user",
                                "content": f"""Analyze this C program and generate {num_tests} test cases in JSON format.

C Code:
```c
{c_code}
```

Output format (JSON array):
[
  {{"input": "test_input_1", "output": "expected_output_1"}},
  {{"input": "test_input_2", "output": "expected_output_2"}},
  ...
]

Requirements:
1. Detect if the program uses command-line arguments (argc/argv) or standard input (scanf)
2. Generate diverse test inputs (edge cases: 0, 1, negative; typical: 10, 100; boundary: max values)
3. Predict the expected output for each input
4. Output ONLY the JSON array, no explanations"""
                            }
                        ],
                        "temperature": 0.3,
                        "max_tokens": 2000
                    }
                }
                
                requests.append(request)
                
            except Exception as e:
                print(f"âš ï¸  è·³è¿‡æ–‡ä»¶ {c_file_path}: {e}")
                continue
        
        print(f"âœ… åˆ›å»ºäº† {len(requests)} ä¸ªè¯·æ±‚")
        return requests, file_mapping
    
    def save_batch_file(self, requests):
        """ä¿å­˜ä¸ºJSONLæ ¼å¼"""
        batch_file_path = os.path.join(self.output_dir, "batch_requests.jsonl")
        
        print(f"\nğŸ’¾ ä¿å­˜batchæ–‡ä»¶: {batch_file_path}")
        
        with open(batch_file_path, 'w') as f:
            for req in requests:
                f.write(json.dumps(req) + '\n')
        
        print(f"âœ… ä¿å­˜å®Œæˆï¼Œå…± {len(requests)} è¡Œ")
        return batch_file_path
    
    def submit_batch(self, batch_file_path):
        """æäº¤batchä»»åŠ¡"""
        print(f"\nğŸ“¤ ä¸Šä¼ batchæ–‡ä»¶...")
        
        try:
            # ä¸Šä¼ æ–‡ä»¶
            with open(batch_file_path, 'rb') as f:
                batch_file = self.client.files.create(
                    file=f,
                    purpose='batch'
                )
            
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {batch_file.id}")
            
            # åˆ›å»ºbatchä»»åŠ¡
            print(f"\nğŸš€ åˆ›å»ºbatchä»»åŠ¡...")
            batch = self.client.batches.create(
                input_file_id=batch_file.id,
                endpoint="/v1/chat/completions",
                completion_window="24h"
            )
            
            print(f"âœ… Batchä»»åŠ¡åˆ›å»ºæˆåŠŸ!")
            print(f"   Batch ID: {batch.id}")
            print(f"   çŠ¶æ€: {batch.status}")
            
            # ä¿å­˜batchä¿¡æ¯
            batch_info_path = os.path.join(self.output_dir, "batch_info.json")
            with open(batch_info_path, 'w') as f:
                json.dump({
                    "batch_id": batch.id,
                    "file_id": batch_file.id,
                    "status": batch.status,
                    "created_at": str(batch.created_at),
                    "request_counts": getattr(batch, 'request_counts', {})
                }, f, indent=2)
            
            return batch.id
            
        except Exception as e:
            print(f"âŒ æäº¤å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def wait_for_completion(self, batch_id, max_wait_minutes=30):
        """ç­‰å¾…batchå®Œæˆ"""
        print(f"\nâ³ ç­‰å¾…batchå®Œæˆ (æœ€å¤š {max_wait_minutes} åˆ†é’Ÿ)...")
        print(f"   Tip: ä½ å¯ä»¥å…³é—­ç¨‹åºï¼Œç¨åç”¨batch_idæŸ¥è¯¢ç»“æœ")
        
        max_checks = max_wait_minutes * 2  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
        
        for i in range(max_checks):
            try:
                batch = self.client.batches.retrieve(batch_id)
                
                status = batch.status
                request_counts = getattr(batch, 'request_counts', {})
                
                print(f"\r   [{i+1}/{max_checks}] çŠ¶æ€: {status} | "
                      f"å®Œæˆ: {request_counts.get('completed', 0)}/{request_counts.get('total', 0)}", 
                      end='', flush=True)
                
                if status == "completed":
                    print("\n\nâœ… Batchå®Œæˆï¼")
                    return batch
                    
                elif status in ["failed", "expired", "cancelled"]:
                    print(f"\n\nâŒ Batchå¤±è´¥: {status}")
                    return None
                
                time.sleep(30)  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
                
            except Exception as e:
                print(f"\nâš ï¸  æ£€æŸ¥çŠ¶æ€æ—¶å‡ºé”™: {e}")
                time.sleep(30)
                continue
        
        print(f"\n\nâ° è¶…æ—¶: {max_wait_minutes}åˆ†é’Ÿå†…æœªå®Œæˆ")
        print(f"   Batchä»åœ¨è¿è¡Œï¼Œç¨åå¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥è¯¢:")
        print(f"   python3 -c \"from openai import OpenAI; client = OpenAI(...); print(client.batches.retrieve('{batch_id}'))\"")
        return None
    
    def download_results(self, batch):
        """ä¸‹è½½ç»“æœ"""
        print(f"\nğŸ“¥ ä¸‹è½½ç»“æœ...")
        
        try:
            # ä¸‹è½½ç»“æœæ–‡ä»¶
            result_file = self.client.files.content(batch.output_file_id)
            
            # è§£æJSONL
            results = []
            for line in result_file.text.split('\n'):
                if line.strip():
                    results.append(json.loads(line))
            
            print(f"âœ… ä¸‹è½½å®Œæˆï¼Œå…± {len(results)} ä¸ªç»“æœ")
            
            # ä¿å­˜åŸå§‹ç»“æœ
            results_path = os.path.join(self.output_dir, "batch_results.jsonl")
            with open(results_path, 'w') as f:
                f.write(result_file.text)
            
            return results
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            return []
    
    def process_results(self, results, file_mapping):
        """å¤„ç†ç»“æœ"""
        print(f"\nğŸ“Š å¤„ç†ç»“æœ...")
        
        success_count = 0
        failed_count = 0
        
        for result in results:
            custom_id = result.get('custom_id')
            c_file_path = file_mapping.get(custom_id)
            
            if not c_file_path:
                continue
            
            if 'error' in result:
                print(f"âŒ {custom_id}: {result['error']}")
                failed_count += 1
                continue
            
            try:
                # æå–å“åº”
                response_body = result['response']['body']
                content = response_body['choices'][0]['message']['content']
                
                # è§£æJSONæµ‹è¯•ç”¨ä¾‹
                # å°è¯•ä»contentä¸­æå–JSON
                import re
                json_match = re.search(r'\[.*\]', content, re.DOTALL)
                if json_match:
                    test_cases = json.loads(json_match.group())
                    
                    # ä¿å­˜æµ‹è¯•ç”¨ä¾‹
                    c_filename = os.path.basename(c_file_path).replace('.c', '')
                    output_path = os.path.join(self.output_dir, f"{c_filename}_tests.json")
                    
                    with open(output_path, 'w') as f:
                        json.dump(test_cases, f, indent=2)
                    
                    success_count += 1
                    print(f"âœ… {custom_id}: ç”Ÿæˆ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
                else:
                    print(f"âš ï¸  {custom_id}: æ— æ³•è§£æJSON")
                    failed_count += 1
                    
            except Exception as e:
                print(f"âš ï¸  {custom_id}: å¤„ç†å¤±è´¥ - {e}")
                failed_count += 1
        
        print(f"\n" + "="*80)
        print(f"ğŸ“Š ç»“æœç»Ÿè®¡")
        print(f"="*80)
        print(f"âœ… æˆåŠŸ: {success_count}")
        print(f"âŒ å¤±è´¥: {failed_count}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir}")
        
        return success_count, failed_count
    
    def run(self, sample_size=100, num_tests=8, max_wait_minutes=30):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        
        # 1. æ”¶é›†Cæ–‡ä»¶
        c_files = self.collect_c_files(sample_size)
        
        if not c_files:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°Cæ–‡ä»¶")
            return
        
        # 2. åˆ›å»ºbatchè¯·æ±‚
        requests, file_mapping = self.create_batch_requests(c_files, num_tests)
        
        if not requests:
            print("âŒ æ²¡æœ‰åˆ›å»ºä»»ä½•è¯·æ±‚")
            return
        
        # ä¿å­˜æ–‡ä»¶æ˜ å°„
        mapping_path = os.path.join(self.output_dir, "file_mapping.json")
        with open(mapping_path, 'w') as f:
            json.dump(file_mapping, f, indent=2)
        
        # 3. ä¿å­˜batchæ–‡ä»¶
        batch_file_path = self.save_batch_file(requests)
        
        # 4. æäº¤batch
        batch_id = self.submit_batch(batch_file_path)
        
        if not batch_id:
            print("âŒ Batchæäº¤å¤±è´¥")
            return
        
        # 5. ç­‰å¾…å®Œæˆ
        batch = self.wait_for_completion(batch_id, max_wait_minutes)
        
        if not batch:
            print("âš ï¸  Batchæœªåœ¨é¢„æœŸæ—¶é—´å†…å®Œæˆ")
            return
        
        # 6. ä¸‹è½½ç»“æœ
        results = self.download_results(batch)
        
        if not results:
            print("âŒ æ²¡æœ‰è·å–åˆ°ç»“æœ")
            return
        
        # 7. å¤„ç†ç»“æœ
        self.process_results(results, file_mapping)
        
        print(f"\nâœ… å®Œæˆï¼è¾“å‡ºç›®å½•: {self.output_dir}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Batch APIæ‰¹é‡ç¿»è¯‘')
    parser.add_argument('--sample-size', type=int, default=100, help='å¤„ç†æ–‡ä»¶æ•°é‡')
    parser.add_argument('--num-tests', type=int, default=8, help='æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆçš„æµ‹è¯•æ•°é‡')
    parser.add_argument('--max-wait', type=int, default=30, help='æœ€å¤§ç­‰å¾…æ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰')
    
    args = parser.parse_args()
    
    translator = BatchAPITranslator()
    translator.run(
        sample_size=args.sample_size,
        num_tests=args.num_tests,
        max_wait_minutes=args.max_wait
    )

if __name__ == "__main__":
    main()

