#!/usr/bin/env python3
"""
ä½¿ç”¨SACToRæ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
"""

import os
import subprocess
import json
import time
import random
from pathlib import Path
from typing import Dict, List
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class BatchTestGenerator:
    def __init__(self, max_workers: int = 4, num_tests_per_file: int = 10, process_all: bool = True):
        from datetime import datetime
        
        # CodeNet åŸå§‹æ•°æ®ç›®å½•
        self.codenet_data_dir = "/home/changdi/CodeNet/new-data"
        
        # è¾“å‡ºç›®å½•ï¼šä¿æŒä¸è¾“å…¥ç›¸åŒçš„ç»“æ„
        self.output_base_dir = "/home/changdi/sactor/generated_tests"
        os.makedirs(self.output_base_dir, exist_ok=True)
        
        self.max_workers = max_workers
        self.num_tests_per_file = num_tests_per_file
        self.process_all = process_all
        self.lock = threading.Lock()  # ç”¨äºçº¿ç¨‹å®‰å…¨çš„è®¡æ•°å™¨æ›´æ–°
        
        # ç»Ÿè®¡è®¡æ•°å™¨ï¼ˆç”¨äºè®¡ç®—å‡†ç¡®ç‡ï¼‰
        self.success_count = 0
        self.total_count = 0
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = os.path.join(self.output_base_dir, "logs")
        os.makedirs(log_dir, exist_ok=True)
        
        # åˆ›å»º CSV æ—¥å¿—æ–‡ä»¶
        from datetime import datetime
        date_str = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.csv_log_file = os.path.join(log_dir, f"generation_log_{date_str}.csv")
        with open(self.csv_log_file, 'w') as f:
            f.write("timestamp,problem_dir,c_file,c_file_path,success,processing_time,test_count,success_rate,error\n")
        
        print("=" * 80)
        print("ğŸ¯ æ‰¹é‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨é…ç½®")
        print("=" * 80)
        print(f"ğŸ“ æ•°æ®é›†æ¥æº: {self.codenet_data_dir}")
        print(f"   - æ•°æ®é›†ç±»å‹: CodeNet new-data")
        print(f"   - ç›®å½•ç»“æ„: {self.codenet_data_dir}/p*/C/*.c")
        print(f"ğŸ“ è¾“å‡ºåŸºç¡€ç›®å½•: {self.output_base_dir}")
        print(f"   - è¾“å‡ºç»“æ„: {self.output_base_dir}/p*/C/xxx.c.json")
        print(f"ğŸ”§ å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°: {self.max_workers}")
        print(f"ğŸ“ æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆæµ‹è¯•æ•°: {self.num_tests_per_file}")
        print(f"ğŸ¯ å¤„ç†æ¨¡å¼: {'æ‰€æœ‰æ–‡ä»¶' if self.process_all else 'éšæœºé‡‡æ ·'}")
        print(f"ğŸ“ CSV æ—¥å¿—æ–‡ä»¶: {self.csv_log_file}")
        print("=" * 80)
    
    def is_valid_c_file(self, file_path: str) -> bool:
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ C æ–‡ä»¶ï¼ˆè€Œé C++ï¼‰"""
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read(10000)  # è¯»å–æ›´å¤šå†…å®¹æ¥æ£€æŸ¥
                
                # C++ ç‰¹å¾å…³é”®è¯
                cpp_indicators = [
                    '#include <iostream>',
                    '#include <string>',
                    '#include <vector>',
                    '#include <algorithm>',
                    'using namespace std',
                    'std::',
                    'cout',
                    'cin',
                    'endl',
                    'class ',
                    'template<',
                    'namespace '
                ]
                
                for indicator in cpp_indicators:
                    if indicator in content:
                        return False
                
                # åŸºæœ¬è¯­æ³•æ£€æŸ¥ï¼šèŠ±æ‹¬å·åŒ¹é…
                open_braces = content.count('{')
                close_braces = content.count('}')
                if open_braces != close_braces:
                    return False
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ main å‡½æ•°
                if 'main' not in content:
                    return False
                
                # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆå¤ªå°å¯èƒ½ä¸å®Œæ•´ï¼Œå¤ªå¤§å¯èƒ½æœ‰é—®é¢˜ï¼‰
                if len(content) < 50 or len(content) > 50000:
                    return False
                
                return True
        except Exception:
            return False
    
    def collect_all_c_files(self) -> List[str]:
        """æ”¶é›†æ¯ä¸ªé—®é¢˜çš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆ C æ–‡ä»¶
        
        ç­–ç•¥ï¼š
        - æ¯ä¸ªé—®é¢˜ï¼ˆproblemï¼‰åªé€‰æ‹©ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„Cæ–‡ä»¶
        - å¦‚æœè¯¥é—®é¢˜å·²æœ‰JSONï¼ˆè‡³å°‘1ä¸ªï¼‰ï¼Œè·³è¿‡æ•´ä¸ªé—®é¢˜
        """
        print(f"ğŸ” æ‰«æ CodeNet é—®é¢˜ç›®å½•...")
        
        # è·å–æ‰€æœ‰é—®é¢˜ç›®å½•ï¼ˆp*ï¼‰
        selected_c_files = []
        skipped_invalid = 0
        skipped_has_json = 0
        
        problem_dirs = sorted([item for item in os.listdir(self.codenet_data_dir) 
                              if os.path.isdir(os.path.join(self.codenet_data_dir, item)) and item.startswith('p')])
        
        print(f"   æ‰¾åˆ° {len(problem_dirs)} ä¸ªé—®é¢˜ç›®å½•")
        
        for idx, problem_dir_name in enumerate(problem_dirs):
            problem_dir = os.path.join(self.codenet_data_dir, problem_dir_name)
            c_dir = os.path.join(problem_dir, 'C')
            
            if not os.path.exists(c_dir):
                continue
            
            # æ£€æŸ¥è¾“å‡ºç›®å½•æ˜¯å¦å·²æœ‰JSON
            output_problem_dir = os.path.join(self.output_base_dir, problem_dir_name, 'C')
            if os.path.exists(output_problem_dir):
                # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½• .json æ–‡ä»¶
                existing_jsons = [f for f in os.listdir(output_problem_dir) if f.endswith('.json')]
                if existing_jsons:
                    skipped_has_json += 1
                    if (idx + 1) % 100 == 0:
                        print(f"   è¿›åº¦: {idx + 1}/{len(problem_dirs)} ç›®å½•, â­ï¸  è·³è¿‡ {problem_dir_name} (å·²æœ‰JSON)")
                    continue
            
            # è·å–è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰Cæ–‡ä»¶ï¼ŒæŒ‰åå­—æ’åº
            c_files = sorted([os.path.join(c_dir, f) for f in os.listdir(c_dir) if f.endswith('.c')])
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„Cæ–‡ä»¶
            found_valid = False
            for c_file in c_files:
                if self.is_valid_c_file(c_file):
                    selected_c_files.append(c_file)
                    found_valid = True
                    break  # åªå–ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„
                else:
                    skipped_invalid += 1
            
            if not found_valid and len(c_files) > 0:
                # è¯¥é—®é¢˜çš„æ‰€æœ‰Cæ–‡ä»¶éƒ½æ— æ•ˆ
                pass
            
            # æ¯å¤„ç†100ä¸ªç›®å½•æ‰“å°ä¸€æ¬¡è¿›åº¦
            if (idx + 1) % 100 == 0:
                print(f"   è¿›åº¦: {idx + 1}/{len(problem_dirs)} ç›®å½•, å·²é€‰æ‹© {len(selected_c_files)} ä¸ªé—®é¢˜")
        
        print(f"\nğŸ“Š ç»Ÿè®¡:")
        print(f"   âœ… é€‰æ‹©äº† {len(selected_c_files)} ä¸ªé—®é¢˜çš„ç¬¬ä¸€ä¸ªæœ‰æ•ˆCæ–‡ä»¶")
        print(f"   â­ï¸  è·³è¿‡ {skipped_has_json} ä¸ªé—®é¢˜ï¼ˆå·²æœ‰JSONï¼‰")
        print(f"   âŒ è·³è¿‡ {skipped_invalid} ä¸ªæ— æ•ˆæ–‡ä»¶ï¼ˆC++/è¯­æ³•é”™è¯¯/ä¸å®Œæ•´ï¼‰")
        return selected_c_files
    
    def generate_test_for_file(self, c_file_path: str, num_tests: int = 10) -> Dict:
        """ä¸ºå•ä¸ªCæ–‡ä»¶ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        c_filename = os.path.basename(c_file_path)
        
        # æå–é—®é¢˜ç›®å½•åï¼ˆä¾‹å¦‚ p00000ï¼‰
        # c_file_pathæ ¼å¼: /home/changdi/CodeNet/new-data/p00000/C/xxx.c
        parts = c_file_path.split(os.sep)
        problem_dir = None
        for i, part in enumerate(parts):
            if part.startswith('p') and len(part) == 6 and i+1 < len(parts) and parts[i+1] == 'C':
                problem_dir = part
                break
        
        if not problem_dir:
            print(f"âš ï¸  æ— æ³•ä»è·¯å¾„æå–é—®é¢˜ç›®å½•: {c_file_path}")
            problem_dir = "unknown"
        
        # åˆ›å»ºè¾“å‡ºç›®å½•ï¼šä¿æŒä¸è¾“å…¥ç›¸åŒçš„ç»“æ„
        # è¾“å‡ºç»“æ„: /home/changdi/sactor/generated_tests/p00000/C/xxx.c.json
        output_problem_dir = os.path.join(self.output_base_dir, problem_dir, 'C')
        os.makedirs(output_problem_dir, exist_ok=True)
        
        # è¾“å‡ºæ–‡ä»¶è·¯å¾„
        output_test_samples = os.path.join(output_problem_dir, f"{c_filename}.json")
        
        # æ³¨æ„ï¼šè·³è¿‡é€»è¾‘å·²ç»åœ¨ collect_all_c_files() ä¸­å¤„ç†äº†
        # è¿™é‡Œä¸éœ€è¦å†æ£€æŸ¥ï¼Œå› ä¸ºèƒ½åˆ°è¿™é‡Œçš„æ–‡ä»¶éƒ½æ˜¯éœ€è¦ç”Ÿæˆçš„
        
        # æ„å»ºDockerå‘½ä»¤ - åªç”Ÿæˆ test_samples.json
        c_file_dir = os.path.dirname(c_file_path)
        output_filename = os.path.basename(output_test_samples)
        
        cmd = [
            "docker", "run", "--rm",
            "-v", f"{c_file_dir}:/data/c_files",
            "-v", f"/home/changdi/sactor/sactor.toml:/app/sactor.toml",
            "-v", f"{output_problem_dir}:/app/output",
            "sactor", "generate-tests",
            f"/data/c_files/{c_filename}",
            str(num_tests),
            "--type", "bin",
            "--feed-as-stdin",  # CodeNet programs use stdin
            "--out-test-sample-path", f"/app/output/{output_filename}"
        ]
        
        print(f"\nğŸš€ ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {c_filename}")
        print(f"   ğŸ“‚ Cæ–‡ä»¶: {c_file_path}")
        print(f"   ğŸ“ é—®é¢˜ç›®å½•: {problem_dir}")
        print(f"   ğŸ’¾ è¾“å‡º: {output_test_samples}")
        print(f"   ğŸ² æµ‹è¯•æ•°é‡: {num_tests}")
        print(f"\nâ–¶ï¸  å¼€å§‹ç”Ÿæˆ...\n")
        print("=" * 80)
        
        start_time = time.time()
        
        try:
            result = subprocess.run(
                cmd, 
                timeout=120,
                capture_output=True,
                text=True
            )  # 2åˆ†é’Ÿtimeout
            
            processing_time = time.time() - start_time
            print("=" * 80)
            print(f"\nâ±ï¸  ç”Ÿæˆè€—æ—¶: {processing_time:.2f} ç§’")
            
            # æ‰“å°è¯¦ç»†çš„é”™è¯¯è¾“å‡ºï¼ˆç‰¹åˆ«æ˜¯APIé…é¢é”™è¯¯ï¼‰
            if result.stderr:
                stderr_lower = result.stderr.lower()
                # æ£€æµ‹å„ç§é”™è¯¯ç±»å‹
                if '403' in result.stderr or '429' in result.stderr:
                    print("\n" + "!"*80)
                    print("ğŸš« APIé…é¢é”™è¯¯ (403/429):")
                    print("!"*80)
                    # æå–å…³é”®é”™è¯¯ä¿¡æ¯
                    for line in result.stderr.split('\n'):
                        if any(keyword in line.lower() for keyword in ['error', 'quota', '403', '429', 'permission', 'rate limit']):
                            print(f"   {line}")
                    print("!"*80 + "\n")
                elif 'ratelimiterror' in stderr_lower or 'rate limit' in stderr_lower:
                    print("\n" + "!"*80)
                    print("â±ï¸  é€Ÿç‡é™åˆ¶é”™è¯¯:")
                    print("!"*80)
                    for line in result.stderr.split('\n'):
                        if 'rate' in line.lower() or 'limit' in line.lower():
                            print(f"   {line}")
                    print("!"*80 + "\n")
                elif 'permissiondeniederror' in stderr_lower:
                    print("\n" + "!"*80)
                    print("ğŸ”’ æƒé™æ‹’ç»é”™è¯¯:")
                    print("!"*80)
                    for line in result.stderr.split('\n'):
                        if 'permission' in line.lower():
                            print(f"   {line}")
                    print("!"*80 + "\n")
                elif 'insufficient_quota' in stderr_lower or 'quota' in stderr_lower:
                    print("\n" + "!"*80)
                    print("ğŸ’° é…é¢ä¸è¶³é”™è¯¯:")
                    print("!"*80)
                    for line in result.stderr.split('\n'):
                        if 'quota' in line.lower():
                            print(f"   {line}")
                    print("!"*80 + "\n")
                elif 'error' in stderr_lower:
                    # å…¶ä»–é”™è¯¯ä¹Ÿæ˜¾ç¤º
                    print("\n" + "âš ï¸  æ£€æµ‹åˆ°é”™è¯¯ä¿¡æ¯:")
                    for line in result.stderr.split('\n')[-20:]:  # åªæ˜¾ç¤ºæœ€å20è¡Œ
                        if line.strip():
                            print(f"   {line}")
            
            if result.returncode == 0:
                # æ£€æŸ¥è¾“å‡ºæ–‡ä»¶æ˜¯å¦ç”Ÿæˆ
                if os.path.exists(output_test_samples):
                    with open(output_test_samples, 'r') as f:
                        test_samples = json.load(f)
                    
                    return {
                        "success": True,
                        "c_file": c_filename,
                        "c_file_path": c_file_path,
                        "problem_dir": problem_dir,
                        "test_count": len(test_samples),
                        "processing_time": processing_time,
                        "output_file": output_test_samples
                    }
                else:
                    print(f"\nâš ï¸  è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ: {output_test_samples}")
                    
                    # æ˜¾ç¤ºstderrä»¥äº†è§£ä¸ºä»€ä¹ˆæ²¡æœ‰ç”Ÿæˆæ–‡ä»¶
                    if result.stderr:
                        print("\nğŸ“‹ é”™è¯¯è¾“å‡º (å¯èƒ½çš„åŸå› ):")
                        print("-"*80)
                        for line in result.stderr.split('\n')[-30:]:
                            if line.strip():
                                print(f"   {line}")
                        print("-"*80)
                    
                    return {
                        "success": False,
                        "error": f"Output file not generated: {output_test_samples}",
                        "processing_time": processing_time,
                        "c_file": c_filename,
                        "c_file_path": c_file_path,
                        "problem_dir": problem_dir
                    }
            else:
                # æå–è¯¦ç»†é”™è¯¯ä¿¡æ¯
                error_msg = f"Docker command failed with return code: {result.returncode}"
                
                print(f"\n" + "="*80)
                print(f"âŒ å¤±è´¥: {error_msg}")
                print("="*80)
                
                if result.stderr:
                    print("\nğŸ“‹ å®Œæ•´é”™è¯¯è¾“å‡º (stderr):")
                    print("-"*80)
                    # æ˜¾ç¤ºæœ€å50è¡Œstderrï¼ˆé€šå¸¸åŒ…å«æ‰€æœ‰é‡è¦ä¿¡æ¯ï¼‰
                    stderr_lines = result.stderr.split('\n')
                    for line in stderr_lines[-50:]:
                        if line.strip():
                            print(f"   {line}")
                    print("-"*80)
                    
                    # æå–å…³é”®é”™è¯¯è¡Œä¿å­˜åˆ°è¿”å›ç»“æœ
                    error_lines = []
                    for line in result.stderr.split('\n'):
                        if any(keyword in line.lower() for keyword in ['error', 'exception', 'failed', 'quota', '403', '429', 'traceback']):
                            error_lines.append(line.strip())
                    if error_lines:
                        error_msg += f"\nå…³é”®é”™è¯¯: {' | '.join(error_lines[:5])}"
                
                if result.stdout:
                    print("\nğŸ“‹ æ ‡å‡†è¾“å‡º (stdout) æœ€å20è¡Œ:")
                    print("-"*80)
                    stdout_lines = result.stdout.split('\n')
                    for line in stdout_lines[-20:]:
                        if line.strip():
                            print(f"   {line}")
                    print("-"*80)
                
                print()
                
                return {
                    "success": False,
                    "error": error_msg,
                    "processing_time": processing_time,
                    "c_file": c_filename,
                    "c_file_path": c_file_path,
                    "problem_dir": problem_dir
                }
                
        except subprocess.TimeoutExpired as e:
            print(f"\nâ±ï¸  ç”Ÿæˆè¶…æ—¶ï¼æµ‹è¯•ç”Ÿæˆæ—¶é—´è¶…è¿‡ 2 åˆ†é’Ÿ")
            return {
                "success": False,
                "error": "Timeout (2 minutes)",
                "processing_time": 120,
                "c_file": os.path.basename(c_file_path),
                "c_file_path": c_file_path,
                "problem_dir": problem_dir
            }
        except Exception as e:
            error_msg = f"Exception: {str(e)}"
            print(f"\nğŸ’¥ å‘ç”Ÿå¼‚å¸¸: {error_msg}")
            
            # æ‰“å°å †æ ˆè·Ÿè¸ª
            import traceback
            traceback_str = traceback.format_exc()
            print(f"å †æ ˆè·Ÿè¸ª:\n{traceback_str}")
            
            return {
                "success": False,
                "error": error_msg,
                "processing_time": time.time() - start_time,
                "c_file": c_filename,
                "c_file_path": c_file_path,
                "problem_dir": problem_dir
            }
    
    def batch_generate_tests(self) -> Dict:
        """æ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ - å¹¶è¡Œç‰ˆæœ¬ï¼ˆå¤„ç†æ‰€æœ‰Cæ–‡ä»¶ï¼‰"""
        # æ”¶é›†æ‰€æœ‰Cæ–‡ä»¶
        all_c_files = self.collect_all_c_files()
        
        print(f"\nğŸ“Š å°†è¦å¤„ç† {len(all_c_files)} ä¸ªCæ–‡ä»¶")
        
        results = {
            'total': len(all_c_files),
            'success': 0,
            'failed': 0,
            'skipped': 0,  # è·³è¿‡çš„æ–‡ä»¶æ•°é‡
            'total_tests_generated': 0,
            'total_processing_time': 0,
            'details': [],
            'start_time': time.time()
        }
        
        processed_count = 0
        
        # ä½¿ç”¨çº¿ç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_file = {
                executor.submit(self.generate_test_for_file, c_file_path, self.num_tests_per_file): c_file_path 
                for c_file_path in all_c_files
            }
            
            # å¤„ç†å®Œæˆçš„ä»»åŠ¡
            for future in as_completed(future_to_file):
                c_file_path = future_to_file[future]
                processed_count += 1
                
                try:
                    result = future.result()
                    
                    # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»“æœ
                    with self.lock:
                        if result['success']:
                            results['success'] += 1
                            results['total_tests_generated'] += result.get('test_count', result.get('num_tests', 0))
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯è·³è¿‡çš„æ–‡ä»¶
                            if result.get('skipped', False):
                                results['skipped'] += 1
                                success_rate = (results['success'] / processed_count * 100)
                                print(f"\nâ­ï¸  ===== [{processed_count}/{len(all_c_files)}] {os.path.basename(c_file_path)}: å·²è·³è¿‡ (å·²æœ‰ {result.get('num_tests', 0)} ä¸ªæµ‹è¯•) | æˆåŠŸç‡: {success_rate:.1f}% =====\n")
                            else:
                                success_rate = (results['success'] / processed_count * 100)
                                print(f"\nâœ… ===== [{processed_count}/{len(all_c_files)}] {os.path.basename(c_file_path)}: æˆåŠŸç”Ÿæˆ {result.get('test_count', 0)} ä¸ªæµ‹è¯•ç”¨ä¾‹ | æˆåŠŸç‡: {success_rate:.1f}% =====\n")
                        else:
                            results['failed'] += 1
                            success_rate = (results['success'] / processed_count * 100)
                            error_msg = result.get('error', 'Unknown error')
                            print(f"\nâŒ ===== [{processed_count}/{len(all_c_files)}] {os.path.basename(c_file_path)}: å¤±è´¥ | æˆåŠŸç‡: {success_rate:.1f}% =====")
                            print(f"   é”™è¯¯: {error_msg}\n")
                        
                        results['total_processing_time'] += result['processing_time']
                        results['details'].append(result)
                        
                        # å®æ—¶ä¿å­˜åˆ° CSV
                        self._log_result_to_csv(result)
                        
                        # æ¯å¤„ç†5ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡è¿›åº¦
                        if processed_count % 5 == 0:
                            self._save_progress(results, processed_count)
                            
                except Exception as e:
                    with self.lock:
                        results['failed'] += 1
                        success_rate = (results['success'] / processed_count * 100)
                        print(f"\nâŒ ===== [{processed_count}/{len(all_c_files)}] {os.path.basename(c_file_path)}: å¼‚å¸¸ | æˆåŠŸç‡: {success_rate:.1f}% =====")
                        print(f"   ğŸ’¥ Exception: {str(e)}")
                        import traceback
                        print(f"   å †æ ˆè·Ÿè¸ª:\n{traceback.format_exc()}\n")
                        
                        error_result = {
                            'success': False,
                            'error': f"Exception in worker: {str(e)}",
                            'c_file': os.path.basename(c_file_path),
                            'processing_time': 0,
                            'test_count': 0
                        }
                        results['details'].append(error_result)
                        
                        # ä¿å­˜åˆ° CSV
                        self._log_result_to_csv(error_result)
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        
        # è®¡ç®—å¹³å‡å€¼
        if results['total'] > 0:
            results['avg_processing_time'] = results['total_processing_time'] / results['total']
            results['avg_tests_per_file'] = results['total_tests_generated'] / results['success'] if results['success'] > 0 else 0
        
        return results
    
    def _log_result_to_csv(self, result: Dict):
        """å°†å•ä¸ªç»“æœå®æ—¶ä¿å­˜åˆ° CSVï¼ˆåŒ…å«å‡†ç¡®ç‡ï¼‰"""
        try:
            from datetime import datetime
            with self.lock:
                # æ›´æ–°è®¡æ•°å™¨
                self.total_count += 1
                if result.get('success', False):
                    self.success_count += 1
                
                # è®¡ç®—å½“å‰å‡†ç¡®ç‡
                success_rate = (self.success_count / self.total_count * 100) if self.total_count > 0 else 0
                
                timestamp = datetime.now().isoformat()
                problem_dir = result.get('problem_dir', 'unknown')
                c_file = result.get('c_file', 'unknown')
                c_file_path = result.get('c_file_path', '')
                success = result.get('success', False)
                processing_time = result.get('processing_time', 0)
                test_count = result.get('test_count', 0)
                error = str(result.get('error', '')).replace(',', ';').replace('\n', ' ')[:200]
                
                csv_line = f"{timestamp},{problem_dir},{c_file},{c_file_path},{success},{processing_time:.2f},{test_count},{success_rate:.2f},{error}\n"
                
                with open(self.csv_log_file, 'a') as f:
                    f.write(csv_line)
                    f.flush()  # å¼ºåˆ¶åˆ·æ–°åˆ°ç£ç›˜
                
                # è°ƒè¯•ä¿¡æ¯
                print(f"   ğŸ“Š CSVå·²ä¿å­˜: {c_file} | å‡†ç¡®ç‡: {success_rate:.1f}%")
        except Exception as e:
            print(f"âš ï¸ CSV æ—¥å¿—ä¿å­˜å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    def _save_progress(self, results: Dict, processed_count: int):
        """ä¿å­˜è¿›åº¦"""
        progress_file = os.path.join(self.output_base_dir, "logs", f"progress_{processed_count}.json")
        with open(progress_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {processed_count}/{results['total']} æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='SACToR æ‰¹é‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ï¼ˆå¤„ç†æ‰€æœ‰Cæ–‡ä»¶ï¼‰')
    parser.add_argument('--workers', type=int, default=15, help='å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š15ï¼‰')
    parser.add_argument('--num-tests', type=int, default=8, help='æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ•°é‡ï¼ˆé»˜è®¤ï¼š8ï¼‰')
    args = parser.parse_args()
    
    print("ğŸš€ SACToR æ‰¹é‡æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå™¨ (å¤„ç†æ‰€æœ‰Cæ–‡ä»¶)")
    print("=" * 60)
    print(f"ğŸ”§ é…ç½®: ")
    print(f"   - å¤„ç†æ¨¡å¼: æ‰€æœ‰Cæ–‡ä»¶")
    print(f"   - å¹¶è¡Œçº¿ç¨‹æ•°: {args.workers}")
    print(f"   - æ¯ä¸ªæ–‡ä»¶æµ‹è¯•æ•°: {args.num_tests}")
    print("=" * 60)
    
    generator = BatchTestGenerator(
        max_workers=args.workers, 
        num_tests_per_file=args.num_tests,
        process_all=True
    )
    
    try:
        # æ‰¹é‡ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
        results = generator.batch_generate_tests()
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•ç”Ÿæˆç»“æœ:")
        print(f"=" * 60)
        print(f"ğŸ“ æ–‡ä»¶å¤„ç†:")
        print(f"   - å¤„ç†æ–‡ä»¶æ•°: {results['total']}")
        print(f"   - ç”ŸæˆæˆåŠŸ: {results['success']} (å…¶ä¸­è·³è¿‡: {results.get('skipped', 0)})")
        print(f"   - ç”Ÿæˆå¤±è´¥: {results['failed']}")
        print(f"   - æˆåŠŸç‡: {results['success']/results['total']*100:.1f}%")
        print(f"\nğŸ§ª æµ‹è¯•ç”¨ä¾‹:")
        print(f"   - æ€»æµ‹è¯•ç”¨ä¾‹æ•°: {results['total_tests_generated']}")
        print(f"   - å¹³å‡æ¯æ–‡ä»¶: {results['avg_tests_per_file']:.1f} ä¸ª")
        print(f"\nâ±ï¸  å¤„ç†æ—¶é—´:")
        print(f"   - æ€»å¤„ç†æ—¶é—´: {results['duration']:.2f} ç§’ ({results['duration']/60:.1f} åˆ†é’Ÿ)")
        print(f"   - å¹³å‡æ¯æ–‡ä»¶: {results['avg_processing_time']:.2f} ç§’")
        if results['success'] > 0:
            print(f"   - å¹³å‡æ¯æˆåŠŸ: {results['total_processing_time']/results['success']:.2f} ç§’")
        print(f"\nğŸ’° API æˆæœ¬: (æµ‹è¯•ç”Ÿæˆé€šå¸¸éœ€è¦ API è°ƒç”¨)")
        print(f"   - é¢„ä¼°è°ƒç”¨æ¬¡æ•°: ~{results['success'] * 2} æ¬¡")  # ä¼°ç®—
        print(f"=" * 60)
        
        # æ˜¾ç¤ºé…ç½®å½±å“
        print(f"\nğŸ’¡ é…ç½®æ±‡æ€»:")
        print(f"   - æ¯ä¸ªæ–‡ä»¶è¯·æ±‚ç”Ÿæˆ: {args.num_tests} ä¸ªæµ‹è¯•")
        print(f"   - å®é™…å¹³å‡ç”Ÿæˆ: {results['avg_tests_per_file']:.1f} ä¸ªæµ‹è¯•")
        print(f"   - å¹¶è¡Œçº¿ç¨‹æ•°: {args.workers}")
        if results['duration'] > 0:
            throughput = results['total'] / (results['duration'] / 60)
            print(f"   - å¤„ç†ååé‡: {throughput:.1f} ä¸ªæ–‡ä»¶/åˆ†é’Ÿ")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(generator.output_base_dir, "logs", "generation_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°:")
        print(f"   JSON: {results_file}")
        print(f"   CSV:  {generator.csv_log_file}")
        print(f"ğŸ“ ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ä¿å­˜åœ¨: {generator.output_base_dir}")
        print(f"   ç»“æ„: {generator.output_base_dir}/p*/C/*.c.json")
        
        return results
        
    except KeyboardInterrupt:
        print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")

if __name__ == "__main__":
    main()
