import subprocess
from typing import Callable, override

from sactor import utils
from sactor.llm import LLM
from sactor.sactor import CParser

from .test_generator import TestGenerator


class ExecutableTestGenerator(TestGenerator):
    def __init__(
        self,
        llm: LLM,
        c_parser: CParser,
        test_samples,
        executable,
        feed_as_arguments=True,
        input_document=None,
    ):
        super().__init__(
            llm=llm,
            test_samples=test_samples,
            c_parser=c_parser,
            input_document=input_document
        )
        self.executable = executable
        self.feed_as_arguments = feed_as_arguments

        # Check if test samples are valid
        for sample in self.init_test_samples:
            self._execute_test_sample(sample)

    def _execute_test_sample(self, test_sample):
        if self.feed_as_arguments:
            feed_input_str = f'{self.executable} {test_sample}'
            cmd = feed_input_str.split()
            result = subprocess.run(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
        else:
            cmd = self.executable
            result = subprocess.run(
                cmd,
                input=test_sample.encode(),
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
        if result.returncode != 0:
            raise ValueError(
                f"Failed to run the executable with the input: {test_sample}"
            )
        return result.stdout.decode().strip()

    @override
    def generate(self, count):
        # Generate test cases
        prompt = '''
You are an expert to write end-to-end tests for a C program.
'''

        main_code = self.c_parser.extract_function_code("main")
        if main_code is None:
            raise ValueError("No main function found in the C program")

        prompt += f'''
The C program has the following main function:
```c
{main_code}
```
'''
        if self.input_document:
            prompt += f'''
The C program has the following inormation in its documentation:
{self.input_document}
'''
        if len(self.test_samples) > 0:
            prompt += f'''
The C program has the following test cases already written:
'''
            for i, sample in enumerate(self.test_samples):
                prompt += f'''
----INPUT {i}----
```
{sample}
```
----END INPUT {i}----
'''

        prompt += f'''
Please write {count} test cases for the C program (start from i=1). All test cases should be written with the following format:
----INPUT {{i}}----
```
Your input i here, **DO NOT** provide any comments or extra information in this block
```
----END INPUT {{i}}----
----INPUT {{i+1}}----
```
Your input i+1 here, **DO NOT** provide any comments or extra information in this block
```
----END INPUT {{i+1}}----

You don't need to provide the expected output. The expected output will be generated by the system.
'''

        result = self.llm.query(prompt)
        success_count = 0
        for i in range(1, count + 1):
            try:
                test_case = utils.parse_llm_result(result, f"input {i}")
                self.test_samples.append(test_case[f"input {i}"].strip())
                success_count += 1
            except ValueError as _:
                self.generate(count - success_count)  # Retry

        # collect test cases
        for i, sample in enumerate(self.test_samples):
            output = self._execute_test_sample(sample)
            self.test_samples_output.append(
                {
                    "input": sample,
                    "output": output,
                }
            )
