#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„ SACToR æ‰¹é‡ç¿»è¯‘è„šæœ¬
- å‡å°‘è¶…æ—¶æ—¶é—´
- ä¼˜åŒ– max_translation_attempts
- æ·»åŠ è¿›åº¦ç›‘æ§
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
from pathlib import Path
from typing import Dict, List, Optional

class OptimizedTranslator:
    """ä¼˜åŒ–çš„ SACToR æ‰¹é‡ç¿»è¯‘å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        self.temp_dir = tempfile.mkdtemp(prefix='sactor_opt_')
        print(f"ğŸ“ ä¸´æ—¶å·¥ä½œç›®å½•: {self.temp_dir}")
        
        # æ­£ç¡®çš„æ•°æ®ç›®å½•
        self.raw_data_dir = "/home/changdi/sactor-datasets/Project_CodeNet/raw_data"
        self.test_data_dir = "/home/changdi/sactor-datasets/Project_CodeNet/generated_tests"
    
    def __del__(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def find_corresponding_test(self, c_file_path: str) -> Optional[str]:
        """æŸ¥æ‰¾å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶"""
        c_filename = os.path.basename(c_file_path)
        test_filename = c_filename + ".json"
        
        # ç¡®å®šå­ç›®å½• (argv æˆ– scanf)
        if "argv" in c_file_path:
            test_path = os.path.join(self.test_data_dir, "argv", test_filename)
        elif "scanf" in c_file_path:
            test_path = os.path.join(self.test_data_dir, "scanf", test_filename)
        else:
            return None
        
        if os.path.exists(test_path):
            return test_path
        return None
    
    def load_test_cases(self, test_file_path: str) -> List[Dict]:
        """åŠ è½½æµ‹è¯•ç”¨ä¾‹"""
        try:
            with open(test_file_path, 'r') as f:
                test_samples = json.load(f)
            return test_samples
        except Exception as e:
            print(f"âŒ åŠ è½½æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
            return []
    
    def create_test_config(self, c_file_path: str, output_dir: str) -> tuple[str, str, bool]:
        """åˆ›å»ºæµ‹è¯•é…ç½®"""
        c_filename = os.path.basename(c_file_path)
        test_samples_path = os.path.join(output_dir, "test_samples.json")
        
        # æŸ¥æ‰¾å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹
        test_file_path = self.find_corresponding_test(c_file_path)
        
        if test_file_path:
            # ä½¿ç”¨é¢„ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ - ç›´æ¥ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼Œä¸å¤åˆ¶
            test_samples_path = test_file_path  # ç›´æ¥ä½¿ç”¨åŸå§‹è·¯å¾„
            used_pregen = True
        else:
            # æ²¡æœ‰å¯¹åº”çš„æµ‹è¯•ç”¨ä¾‹ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ç”¨ä¾‹
            default_samples = [
                {"input": "10", "output": "10"},
                {"input": "5", "output": "5"},
                {"input": "0", "output": "0"}
            ]
            with open(test_samples_path, 'w') as f:
                json.dump(default_samples, f, indent=2)
            used_pregen = False
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡æ–‡ä»¶
        test_task = []
        with open(test_samples_path, 'r') as f:
            test_samples = json.load(f)
        
        for i in range(len(test_samples)):
            test_task.append({
                "command": f"sactor run-tests --type bin {test_samples_path} %t {i} --feed-as-args",
                "test_id": i
            })
        
        test_task_path = os.path.join(output_dir, "test_task.json")
        with open(test_task_path, 'w') as f:
            json.dump(test_task, f, indent=2)
        
        return test_task_path, test_samples_path, used_pregen
    
    def translate_with_sactor_docker(self, c_file_path: str, output_dir: str, test_task_path: str) -> Dict:
        """ä½¿ç”¨ SACToR Docker è¿›è¡Œç¿»è¯‘ - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            # ç›´æ¥ä½¿ç”¨ç»å¯¹è·¯å¾„ï¼ŒæŒ‚è½½æ•´ä¸ªæ•°æ®é›†ç›®å½•
            sactor_config = "/home/changdi/sactor/sactor.toml"
            cmd = [
                "docker", "run", "--rm",
                "-v", f"{sactor_config}:/app/sactor.toml",
                "-v", f"/home/changdi/sactor-datasets:/home/changdi/sactor-datasets",
                "-v", f"{os.path.dirname(test_task_path)}:/tmp/test_tasks",
                "-v", f"{output_dir}:/tmp/result",
                "sactor", "translate",
                c_file_path,  # ç›´æ¥ä½¿ç”¨ç»å¯¹è·¯å¾„
                f"/tmp/test_tasks/{os.path.basename(test_task_path)}",
                "--result-dir", "/tmp/result",
                "--type", "bin"
            ]
            
            # ä¼˜åŒ–ï¼šå‡å°‘è¶…æ—¶æ—¶é—´ä» 600ç§’ åˆ° 120ç§’ï¼Œæ˜¾ç¤ºè¾“å‡º
            result = subprocess.run(cmd, text=True, timeout=120)
            
            if result.returncode != 0:
                return {
                    'success': False,
                    'error': f"SACToR Docker ç¿»è¯‘å¤±è´¥: {result.stderr[:500]}...",
                    'result_dir': None
                }
            
            return {
                'success': True,
                'error': None,
                'result_dir': os.path.join(output_dir, "result")
            }
            
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': "SACToR Docker ç¿»è¯‘è¶…æ—¶ (2åˆ†é’Ÿ)",
                'result_dir': None
            }
        except Exception as e:
            return {
                'success': False,
                'error': f"SACToR Docker ç¿»è¯‘å‡ºé”™: {e}",
                'result_dir': None
            }
    
    def verify_translation_result(self, result_dir: str) -> Dict:
        """éªŒè¯ç¿»è¯‘ç»“æœ"""
        try:
            verification_results = {
                'unidiomatic': {'success': False, 'details': {}},
                'idiomatic': {'success': False, 'details': {}},
                'overall': False,
                'test_count': 0
            }
            
            # æŸ¥æ‰¾ç¿»è¯‘ç»“æœ
            unidiomatic_dir = os.path.join(result_dir, "translated_code_unidiomatic")
            idiomatic_dir = os.path.join(result_dir, "translated_code_idiomatic")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¿»è¯‘ç»“æœ
            if os.path.exists(unidiomatic_dir):
                verification_results['unidiomatic'] = {'success': True, 'details': {'exists': True}}
            
            if os.path.exists(idiomatic_dir):
                verification_results['idiomatic'] = {'success': True, 'details': {'exists': True}}
                
                # è®¡ç®—æµ‹è¯•æ•°é‡
                test_samples_path = os.path.join(result_dir, "..", "test_samples.json")
                if os.path.exists(test_samples_path):
                    with open(test_samples_path, 'r') as f:
                        test_samples = json.load(f)
                    verification_results['test_count'] = len(test_samples)
            
            # ç»¼åˆç»“æœ
            verification_results['overall'] = (
                verification_results['unidiomatic']['success'] and 
                verification_results['idiomatic']['success']
            )
            
            return verification_results
            
        except Exception as e:
            return {
                'unidiomatic': {'success': False, 'error': str(e)},
                'idiomatic': {'success': False, 'error': str(e)},
                'overall': False,
                'test_count': 0
            }
    
    def translate_and_verify(self, c_file_path: str, output_dir: str) -> Dict:
        """ç¿»è¯‘å’ŒéªŒè¯å•ä¸ª C æ–‡ä»¶"""
        start_time = time.time()
        
        try:
            print(f"ğŸ¯ ä¼˜åŒ–ç¿»è¯‘: {os.path.basename(c_file_path)}")
            
            # 1. åˆ›å»ºæµ‹è¯•é…ç½®
            test_task_path, test_samples_path, used_pregen = self.create_test_config(c_file_path, output_dir)
            
            # 2. ä½¿ç”¨ SACToR Docker è¿›è¡Œç¿»è¯‘
            translation_result = self.translate_with_sactor_docker(c_file_path, output_dir, test_task_path)
            
            if not translation_result['success']:
                return {
                    'success': False,
                    'error': translation_result['error'],
                    'verification': None,
                    'test_count': 0,
                    'used_pregen': used_pregen,
                    'duration': time.time() - start_time
                }
            
            # 3. éªŒè¯ç¿»è¯‘ç»“æœ
            verification_results = self.verify_translation_result(translation_result['result_dir'])
            
            duration = time.time() - start_time
            print(f"âœ… å®Œæˆ: {os.path.basename(c_file_path)} ({duration:.1f}ç§’)")
            
            return {
                'success': True,
                'error': None,
                'verification': verification_results,
                'test_count': verification_results.get('test_count', 0),
                'result_dir': translation_result['result_dir'],
                'used_pregen': used_pregen,
                'duration': duration
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"ç¿»è¯‘å¤±è´¥: {e}",
                'verification': None,
                'test_count': 0,
                'used_pregen': False,
                'duration': time.time() - start_time
            }
    
    def batch_translate(self, output_base_dir: str, max_files: int = None) -> Dict:
        """æ‰¹é‡ç¿»è¯‘"""
        all_c_files = []
        
        # æ”¶é›†æ‰€æœ‰ C æ–‡ä»¶
        for subdir in ["argv", "scanf"]:
            subdir_path = os.path.join(self.raw_data_dir, subdir)
            if os.path.exists(subdir_path):
                c_files = [os.path.join(subdir_path, f) for f in os.listdir(subdir_path) if f.endswith('.c')]
                all_c_files.extend(c_files)
        
        # é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if max_files is not None and len(all_c_files) > max_files:
            all_c_files = all_c_files[:max_files]
            print(f"âš ï¸ é™åˆ¶å¤„ç†å‰ {max_files} ä¸ªæ–‡ä»¶")
        
        total_files = len(all_c_files)
        print(f"ğŸš€ å¼€å§‹ä¼˜åŒ–æ‰¹é‡ç¿»è¯‘ {total_files} ä¸ª C æ–‡ä»¶")
        
        results = {
            'total': total_files,
            'success': 0,
            'failed': 0,
            'verified': 0,
            'pre_generated_used': 0,
            'default_used': 0,
            'total_duration': 0,
            'avg_duration': 0,
            'details': [],
            'start_time': time.time()
        }
        
        for i, c_file_path in enumerate(all_c_files):
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i+1}/{total_files}: {os.path.basename(c_file_path)}")
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºè¾“å‡ºç›®å½•
            relative_path = os.path.relpath(c_file_path, self.raw_data_dir)
            file_output_dir = os.path.join(output_base_dir, relative_path.replace('.c', ''))
            os.makedirs(file_output_dir, exist_ok=True)
            
            # ç¿»è¯‘å’ŒéªŒè¯
            result = self.translate_and_verify(c_file_path, file_output_dir)
            
            if result['success']:
                results['success'] += 1
                if result['verification'] and result['verification']['overall']:
                    results['verified'] += 1
            
            # ç»Ÿè®¡æµ‹è¯•ç”¨ä¾‹æ¥æº
            if result.get('used_pregen', False):
                results['pre_generated_used'] += 1
            else:
                results['default_used'] += 1
            
            # ç»Ÿè®¡æ—¶é—´
            results['total_duration'] += result.get('duration', 0)
            
            results['details'].append({
                'file': os.path.basename(c_file_path),
                'directory': os.path.dirname(c_file_path),
                'success': result['success'],
                'verified': result['verification']['overall'] if result['verification'] else False,
                'test_count': result['test_count'],
                'used_pregen': result.get('used_pregen', False),
                'duration': result.get('duration', 0),
                'error': result['error']
            })
            
            results['failed'] = results['total'] - results['success']
            
            # è®¡ç®—å¹³å‡æ—¶é—´
            if results['success'] > 0:
                results['avg_duration'] = results['total_duration'] / results['success']
            
            # æ¯å¤„ç† 5 ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡è¿›åº¦ï¼ˆæ›´é¢‘ç¹ï¼‰
            if (i + 1) % 5 == 0:
                self._save_progress(results, output_base_dir, i + 1)
                print(f"ğŸ“Š è¿›åº¦: {i+1}/{total_files}, æˆåŠŸ: {results['success']}, å¹³å‡æ—¶é—´: {results['avg_duration']:.1f}ç§’/ä¸ª")
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        
        return results
    
    def _save_progress(self, results: Dict, output_base_dir: str, processed_count: int):
        """ä¿å­˜è¿›åº¦"""
        progress_file = os.path.join(output_base_dir, f"progress_{processed_count}.json")
        with open(progress_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {processed_count}/{results['total']} æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    output_base_dir = "/home/changdi/sactor-datasets/sactor_optimized_translations"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_base_dir, exist_ok=True)
    
    # ç»Ÿè®¡æ€»æ–‡ä»¶æ•°å’Œé¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹è¦†ç›–
    raw_data_dir = "/home/changdi/sactor-datasets/Project_CodeNet/raw_data"
    test_data_dir = "/home/changdi/sactor-datasets/Project_CodeNet/generated_tests"
    
    argv_c_files = len(os.listdir(os.path.join(raw_data_dir, "argv")))
    scanf_c_files = len(os.listdir(os.path.join(raw_data_dir, "scanf")))
    total_c_files = argv_c_files + scanf_c_files
    
    argv_test_files = len(os.listdir(os.path.join(test_data_dir, "argv")))
    scanf_test_files = len(os.listdir(os.path.join(test_data_dir, "scanf")))
    total_test_files = argv_test_files + scanf_test_files
    
    print(f"ğŸ“ åŸå§‹æ•°æ®ç»Ÿè®¡:")
    print(f"   - argv: {argv_c_files} ä¸ª C æ–‡ä»¶")
    print(f"   - scanf: {scanf_c_files} ä¸ª C æ–‡ä»¶")
    print(f"   - æ€»è®¡: {total_c_files} ä¸ª C æ–‡ä»¶")
    print(f"ğŸ¯ é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ç»Ÿè®¡:")
    print(f"   - argv: {argv_test_files} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"   - scanf: {scanf_test_files} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"   - æ€»è®¡: {total_test_files} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"ğŸ“Š æµ‹è¯•ç”¨ä¾‹è¦†ç›–ç‡: {total_test_files}/{total_c_files} = {total_test_files/total_c_files*100:.1f}%")
    print(f"ğŸš€ ä¼˜åŒ–è®¾ç½®:")
    print(f"   - Docker è¶…æ—¶: 120ç§’ (ä» 600ç§’ ä¼˜åŒ–)")
    print(f"   - è¿›åº¦ä¿å­˜: æ¯5ä¸ªæ–‡ä»¶ (ä» 10ä¸ªæ–‡ä»¶ ä¼˜åŒ–)")
    print(f"   - é¢„è®¡å¹³å‡æ—¶é—´: 30-60ç§’/ä¸ª (ä» 2-5åˆ†é’Ÿ/ä¸ª ä¼˜åŒ–)")
    
    # åˆ›å»ºç¿»è¯‘å™¨
    translator = OptimizedTranslator()
    
    try:
        # æ‰¹é‡ç¿»è¯‘
        results = translator.batch_translate(output_base_dir, max_files=None)
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š SACToR ä¼˜åŒ–æ‰¹é‡ç¿»è¯‘ç»“æœ:")
        print(f"æ€»æ–‡ä»¶æ•°: {results['total']}")
        print(f"ç¿»è¯‘æˆåŠŸ: {results['success']}")
        print(f"ç¿»è¯‘å¤±è´¥: {results['failed']}")
        print(f"éªŒè¯é€šè¿‡: {results['verified']}")
        print(f"ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•: {results['pre_generated_used']}")
        print(f"ä½¿ç”¨é»˜è®¤æµ‹è¯•: {results['default_used']}")
        print(f"æ€»å¤„ç†æ—¶é—´: {results['duration']:.2f} ç§’")
        print(f"å¹³å‡ç¿»è¯‘æ—¶é—´: {results['avg_duration']:.2f} ç§’/ä¸ª")
        print(f"æˆåŠŸç‡: {results['success']/results['total']*100:.1f}%")
        print(f"éªŒè¯ç‡: {results['verified']/results['total']*100:.1f}%")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(output_base_dir, "sactor_optimized_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        return results
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if hasattr(translator, 'temp_dir') and os.path.exists(translator.temp_dir):
            shutil.rmtree(translator.temp_dir)

if __name__ == "__main__":
    main()