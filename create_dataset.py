#!/usr/bin/env python3
"""
ä»ç¿»è¯‘ç»“æœåˆ›å»ºC2Rustæ•°æ®é›†
æ ¼å¼: åŸå§‹Cæ–‡ä»¶ + å¯¹åº”çš„combined.rs
"""

import os
import json
import argparse
from pathlib import Path


class C2RustDatasetCreator:
    def __init__(self, output_file="c2rust_dataset.jsonl"):
        # æ‰€æœ‰ç¿»è¯‘ç»“æœç›®å½•
        self.translation_dirs = [
            "/home/changdi/sactor/translated_rust_4k",
            "/home/changdi/sactor/translated_rust_4k_34",
            "/home/changdi/sactor/translated_rust_5_to_20",
            "/home/changdi/sactor/translated_rust_21_to_40",
            "/home/changdi/sactor/translated_rust_41_to_80",
        ]
        
        # Cæ–‡ä»¶æ ¹ç›®å½•
        self.c_files_roots = [
            "/home/changdi/CodeNet/test_4k_accept",
            "/home/changdi/CodeNet/test_4k_accept_34",
            "/home/changdi/CodeNet/Project_CodeNet/data",
        ]
        
        self.output_file = output_file
        self.dataset_id_counter = 0
        
        # åŠ è½½5ä¸ªä¸åŒçš„ç³»ç»Ÿæç¤ºè¯
        self.prompts = self._load_prompts()
        self.prompt_index = 0  # è½®æµä½¿ç”¨æç¤ºè¯
    
    def _load_prompts(self):
        """åŠ è½½5ä¸ªä¸åŒçš„æç¤ºè¯"""
        prompt_dir = "/home/changdi/Moxin-C2Rust-Datasets/scripts/instructions/function"
        prompts = []
        
        for i in range(1, 6):
            prompt_file = os.path.join(prompt_dir, f"function_instruction_{i}.txt")
            try:
                with open(prompt_file, 'r', encoding='utf-8') as f:
                    prompt = f.read().strip()
                    prompts.append(prompt + "\n\n")
            except Exception as e:
                print(f"âš ï¸  æ— æ³•åŠ è½½æç¤ºè¯æ–‡ä»¶ {prompt_file}: {e}")
                # ä½¿ç”¨é»˜è®¤æç¤ºè¯ä½œä¸ºå¤‡ä»½
                prompts.append(
                    "You are a C-to-Rust code translator.\n"
                    "Output only the translated Rust function, with no comments or explanations.\n\n"
                    "Requirements\n"
                    "\tâ€¢\tPreserve full functional equivalence.\n"
                    "\tâ€¢\tConvert types accurately; prefer references and slices over pointers.\n"
                    "\tâ€¢\tUse safe Rust by default; mark unsafe only when required.\n"
                    "\tâ€¢\tReplace manual memory operations with Box or Vec.\n"
                    "\tâ€¢\tUse Result/Option instead of raw error codes or nulls.\n"
                    "\tâ€¢\tFollow Rust naming conventions (snake_case).\n"
                    "\tâ€¢\tAvoid external dependencies except libc if necessary.\n\n"
                    "Translate the following C function into idiomatic, safe Rust:\n\n"
                )
        
        if not prompts:
            raise RuntimeError("æ— æ³•åŠ è½½ä»»ä½•æç¤ºè¯æ–‡ä»¶")
        
        print(f"âœ… æˆåŠŸåŠ è½½ {len(prompts)} ä¸ªæç¤ºè¯")
        return prompts
    
    def _get_next_prompt(self):
        """è·å–ä¸‹ä¸€ä¸ªæç¤ºè¯ï¼ˆè½®æµä½¿ç”¨ï¼‰"""
        prompt = self.prompts[self.prompt_index]
        self.prompt_index = (self.prompt_index + 1) % len(self.prompts)
        return prompt
    
    def find_c_file(self, problem_id, submission_id):
        """æŸ¥æ‰¾åŸå§‹Cæ–‡ä»¶"""
        # å°è¯•å„ä¸ªå¯èƒ½çš„ä½ç½®
        possible_paths = [
            # test_4k_accept
            f"/home/changdi/CodeNet/test_4k_accept/{problem_id}/C/{submission_id}.c",
            # test_4k_accept_34
            f"/home/changdi/CodeNet/test_4k_accept_34/{problem_id}/C/{submission_id}.c",
            # åŸå§‹CodeNetæ•°æ®
            f"/home/changdi/CodeNet/Project_CodeNet/data/{problem_id}/C/{submission_id}.c",
        ]
        
        for path in possible_paths:
            if os.path.exists(path):
                return path
        
        return None
    
    def read_file_safely(self, filepath):
        """å®‰å…¨è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                return f.read()
        except UnicodeDecodeError:
            try:
                with open(filepath, 'r', encoding='latin-1') as f:
                    return f.read()
            except Exception as e:
                print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {filepath}: {e}")
                return None
        except Exception as e:
            print(f"âš ï¸  è¯»å–æ–‡ä»¶å‡ºé”™ {filepath}: {e}")
            return None
    
    def collect_translation_pairs(self):
        """æ”¶é›†æ‰€æœ‰ç¿»è¯‘å¯¹"""
        pairs = []
        
        for trans_dir in self.translation_dirs:
            if not os.path.exists(trans_dir):
                print(f"â­ï¸  è·³è¿‡ä¸å­˜åœ¨çš„ç›®å½•: {trans_dir}")
                continue
            
            print(f"ğŸ” æ‰«æ: {trans_dir}")
            
            # éå†æ‰€æœ‰é—®é¢˜ç›®å½•
            for problem_id in sorted(os.listdir(trans_dir)):
                problem_path = os.path.join(trans_dir, problem_id)
                if not os.path.isdir(problem_path):
                    continue
                
                rust_dir = os.path.join(problem_path, "Rust")
                if not os.path.exists(rust_dir):
                    continue
                
                # éå†æ‰€æœ‰æäº¤
                for submission_id in os.listdir(rust_dir):
                    submission_path = os.path.join(rust_dir, submission_id)
                    if not os.path.isdir(submission_path):
                        continue
                    
                    # æŸ¥æ‰¾combined.rs
                    combined_rs = os.path.join(submission_path, 
                                              "translated_code_unidiomatic", 
                                              "combined.rs")
                    
                    if not os.path.exists(combined_rs):
                        continue
                    
                    # æŸ¥æ‰¾åŸå§‹Cæ–‡ä»¶
                    c_file = self.find_c_file(problem_id, submission_id)
                    if not c_file:
                        print(f"âš ï¸  æ‰¾ä¸åˆ°Cæ–‡ä»¶: {problem_id}/{submission_id}")
                        continue
                    
                    # è¯»å–å†…å®¹
                    c_content = self.read_file_safely(c_file)
                    rust_content = self.read_file_safely(combined_rs)
                    
                    if c_content is None or rust_content is None:
                        continue
                    
                    # è·³è¿‡ç©ºæ–‡ä»¶æˆ–è¿‡å°çš„æ–‡ä»¶
                    if len(c_content.strip()) < 10 or len(rust_content.strip()) < 10:
                        continue
                    
                    pairs.append({
                        "problem_id": problem_id,
                        "submission_id": submission_id,
                        "c_file": c_file,
                        "rust_file": combined_rs,
                        "c_content": c_content,
                        "rust_content": rust_content,
                    })
        
        print(f"\nâœ… å…±æ”¶é›†åˆ° {len(pairs)} ä¸ªæœ‰æ•ˆç¿»è¯‘å¯¹")
        return pairs
    
    def create_dataset_entry(self, pair):
        """åˆ›å»ºå•ä¸ªæ•°æ®é›†æ¡ç›®"""
        dataset_id = f"c2rust_{self.dataset_id_counter}"
        self.dataset_id_counter += 1
        
        # è·å–ä¸‹ä¸€ä¸ªæç¤ºè¯ï¼ˆè½®æµä½¿ç”¨5ä¸ªæç¤ºè¯ï¼‰
        # è®°å½•å½“å‰ä½¿ç”¨çš„promptç¼–å·ï¼ˆ1-5ï¼‰
        current_prompt_id = self.prompt_index + 1
        system_prompt = self._get_next_prompt()
        
        # æ„å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆç³»ç»Ÿæç¤º + Cä»£ç ï¼‰
        user_content = system_prompt + pair["c_content"]
        
        # æ„å»ºåŠ©æ‰‹æ¶ˆæ¯ï¼ˆRustä»£ç ï¼‰
        assistant_content = pair["rust_content"]
        
        entry = {
            "dataset": "c2rust",
            "id": dataset_id,
            "problem_id": pair["problem_id"],
            "submission_id": pair["submission_id"],
            "prompt_id": current_prompt_id,  # è®°å½•ä½¿ç”¨çš„æ˜¯å“ªä¸ªprompt (1-5)
            "messages": [
                {
                    "role": "user",
                    "content": user_content
                },
                {
                    "role": "assistant",
                    "content": assistant_content
                }
            ]
        }
        
        return entry
    
    def create_dataset(self, sample_only=False, sample_count=10):
        """åˆ›å»ºæ•°æ®é›†"""
        print("=" * 80)
        print("ğŸš€ C2Rust æ•°æ®é›†ç”Ÿæˆå™¨")
        print("=" * 80)
        
        # æ”¶é›†ç¿»è¯‘å¯¹
        pairs = self.collect_translation_pairs()
        
        if not pairs:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¿»è¯‘å¯¹")
            return
        
        # å¦‚æœåªç”Ÿæˆæ ·æœ¬
        if sample_only:
            pairs = pairs[:sample_count]
            print(f"\nğŸ“ ç”Ÿæˆæ ·æœ¬æ•°æ®é›† (å‰ {sample_count} æ¡)")
        
        # ç”Ÿæˆæ•°æ®é›†
        output_path = self.output_file
        if sample_only:
            output_path = output_path.replace(".jsonl", "_sample.jsonl")
        
        print(f"\nğŸ“ å†™å…¥æ•°æ®é›†: {output_path}")
        
        with open(output_path, 'w', encoding='utf-8') as f:
            for pair in pairs:
                entry = self.create_dataset_entry(pair)
                f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        
        print(f"âœ… æ•°æ®é›†ç”Ÿæˆå®Œæˆ: {len(pairs)} æ¡è®°å½•")
        print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        self.print_statistics(pairs, output_path)
    
    def print_statistics(self, pairs, output_path):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 80)
        print("ğŸ“Š æ•°æ®é›†ç»Ÿè®¡")
        print("=" * 80)
        
        # è®¡ç®—ä»£ç é•¿åº¦ç»Ÿè®¡
        c_lengths = [len(p["c_content"]) for p in pairs]
        rust_lengths = [len(p["rust_content"]) for p in pairs]
        
        print(f"æ€»è®°å½•æ•°: {len(pairs)}")
        print(f"\nCä»£ç é•¿åº¦:")
        print(f"  æœ€å°: {min(c_lengths)} å­—ç¬¦")
        print(f"  æœ€å¤§: {max(c_lengths)} å­—ç¬¦")
        print(f"  å¹³å‡: {sum(c_lengths) // len(c_lengths)} å­—ç¬¦")
        
        print(f"\nRustä»£ç é•¿åº¦:")
        print(f"  æœ€å°: {min(rust_lengths)} å­—ç¬¦")
        print(f"  æœ€å¤§: {max(rust_lengths)} å­—ç¬¦")
        print(f"  å¹³å‡: {sum(rust_lengths) // len(rust_lengths)} å­—ç¬¦")
        
        # æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(output_path)
        print(f"\næ•°æ®é›†æ–‡ä»¶å¤§å°: {file_size / (1024*1024):.2f} MB")
        
        # æŒ‰é—®é¢˜ç»Ÿè®¡
        problems = set(p["problem_id"] for p in pairs)
        print(f"\nè¦†ç›–é—®é¢˜æ•°: {len(problems)}")
        print(f"å¹³å‡æ¯é¢˜æ ·æœ¬æ•°: {len(pairs) / len(problems):.1f}")
        
        # ç»Ÿè®¡promptä½¿ç”¨åˆ†å¸ƒ
        print(f"\nPromptä½¿ç”¨åˆ†å¸ƒ:")
        print(f"  ä½¿ç”¨äº† {len(self.prompts)} ä¸ªä¸åŒçš„prompt")
        print(f"  è½®æµåˆ†é…ï¼Œæ¯ä¸ªpromptçº¦ä½¿ç”¨ {len(pairs) // len(self.prompts)} æ¬¡")
        
        print("=" * 80)


def main():
    parser = argparse.ArgumentParser(description='ä»ç¿»è¯‘ç»“æœåˆ›å»ºC2Rustæ•°æ®é›†')
    parser.add_argument('--output', '-o', default='c2rust_dataset.jsonl',
                       help='è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: c2rust_dataset.jsonl)')
    parser.add_argument('--sample', action='store_true',
                       help='åªç”Ÿæˆæ ·æœ¬æ•°æ®é›† (å‰10æ¡)')
    parser.add_argument('--sample-count', type=int, default=10,
                       help='æ ·æœ¬æ•°é‡ (é»˜è®¤: 10)')
    
    args = parser.parse_args()
    
    creator = C2RustDatasetCreator(output_file=args.output)
    creator.create_dataset(sample_only=args.sample, sample_count=args.sample_count)


if __name__ == "__main__":
    main()

