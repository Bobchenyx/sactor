#!/usr/bin/env python3
"""
ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„æ‰¹é‡ç¿»è¯‘è„šæœ¬
åŸºäº https://github.com/qsdrqs/sactor-datasets/tree/main/Project_CodeNet/generated_tests
"""

import os
import sys
import json
import subprocess
import tempfile
import shutil
import time
from pathlib import Path
from typing import Dict, List, Optional

class PreGeneratedTestTranslator:
    """ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹çš„ SACToR æ‰¹é‡ç¿»è¯‘å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç¿»è¯‘å™¨"""
        # åˆ›å»ºä¸´æ—¶å·¥ä½œç›®å½•
        self.temp_dir = tempfile.mkdtemp(prefix='sactor_pregen_')
        print(f"ğŸ“ ä¸´æ—¶å·¥ä½œç›®å½•: {self.temp_dir}")
        
        # é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ç›®å½•
        self.test_base_dir = "/home/changdi/sactor-datasets/Project_CodeNet/generated_tests"
    
    def __del__(self):
        """æ¸…ç†ä¸´æ—¶ç›®å½•"""
        if hasattr(self, 'temp_dir') and os.path.exists(self.temp_dir):
            shutil.rmtree(self.temp_dir)
    
    def find_pre_generated_tests(self, c_file_path: str) -> Optional[str]:
        """æŸ¥æ‰¾é¢„ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹æ–‡ä»¶"""
        c_filename = os.path.basename(c_file_path)
        test_filename = c_filename + ".json"
        
        # æ£€æŸ¥ argv ç›®å½•
        argv_test_path = os.path.join(self.test_base_dir, "argv", test_filename)
        if os.path.exists(argv_test_path):
            return argv_test_path
        
        # æ£€æŸ¥ scanf ç›®å½•
        scanf_test_path = os.path.join(self.test_base_dir, "scanf", test_filename)
        if os.path.exists(scanf_test_path):
            return scanf_test_path
        
        return None
    
    def load_pre_generated_tests(self, test_file_path: str) -> List[Dict]:
        """åŠ è½½é¢„ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹"""
        try:
            with open(test_file_path, 'r') as f:
                test_samples = json.load(f)
            
            print(f"âœ… åŠ è½½äº† {len(test_samples)} ä¸ªé¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹")
            return test_samples
            
        except Exception as e:
            print(f"âŒ åŠ è½½é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
            return []
    
    def create_test_config_with_pre_generated(self, c_file_path: str, output_dir: str) -> tuple[str, str]:
        """ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹åˆ›å»ºæµ‹è¯•é…ç½®"""
        # æŸ¥æ‰¾é¢„ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
        test_file_path = self.find_pre_generated_tests(c_file_path)
        
        if test_file_path:
            # ä½¿ç”¨é¢„ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹
            test_samples = self.load_pre_generated_tests(test_file_path)
            if test_samples:
                print(f"ğŸ¯ ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹: {os.path.basename(test_file_path)}")
            else:
                # å›é€€åˆ°é»˜è®¤æµ‹è¯•ç”¨ä¾‹
                test_samples = self._get_default_test_samples()
                print(f"âš ï¸ å›é€€åˆ°é»˜è®¤æµ‹è¯•ç”¨ä¾‹")
        else:
            # æ²¡æœ‰æ‰¾åˆ°é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œä½¿ç”¨é»˜è®¤
            test_samples = self._get_default_test_samples()
            print(f"âš ï¸ æœªæ‰¾åˆ°é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹ï¼Œä½¿ç”¨é»˜è®¤æµ‹è¯•ç”¨ä¾‹")
        
        # åˆ›å»ºæµ‹è¯•ä»»åŠ¡æ–‡ä»¶
        test_task = []
        for i in range(len(test_samples)):
            test_task.append({
                "command": f"sactor run-tests --type bin ./test_samples.json %t {i} --feed-as-args",
                "test_id": i
            })
        
        # ä¿å­˜æ–‡ä»¶
        test_task_path = os.path.join(output_dir, "test_task.json")
        with open(test_task_path, 'w') as f:
            json.dump(test_task, f, indent=2)
        
        test_samples_path = os.path.join(output_dir, "test_samples.json")
        with open(test_samples_path, 'w') as f:
            json.dump(test_samples, f, indent=2)
        
        return test_task_path, test_samples_path
    
    def _get_default_test_samples(self) -> List[Dict]:
        """è·å–é»˜è®¤æµ‹è¯•ç”¨ä¾‹"""
        return [
            {"input": "10", "output": "10"},
            {"input": "5", "output": "5"},
            {"input": "0", "output": "0"}
        ]
    
    def translate_with_sactor_docker(self, c_file_path: str, output_dir: str, test_task_path: str) -> Dict:
        """ä½¿ç”¨ SACToR Docker è¿›è¡Œç¿»è¯‘"""
        try:
            # å¤åˆ¶ C æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•
            c_file_dest = os.path.join(output_dir, os.path.basename(c_file_path))
            shutil.copy2(c_file_path, c_file_dest)
            
            # è¿è¡Œ SACToR Docker ç¿»è¯‘
            sactor_config = "/home/changdi/sactor/sactor.toml"
            cmd = [
                "docker", "run", "--rm",
                "-v", f"{sactor_config}:/app/sactor.toml",
                "-v", f"{output_dir}:/tmp/translation",
                "sactor", "translate",
                f"/tmp/translation/{os.path.basename(c_file_path)}",
                f"/tmp/translation/test_task.json",
                "--result-dir", "/tmp/translation/result",
                "--type", "bin"
            ]
            
            # ä½¿ç”¨è¾ƒé•¿çš„è¶…æ—¶æ—¶é—´
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode != 0:
                return {
                    'success': False,
                    'error': f"SACToR Docker ç¿»è¯‘å¤±è´¥: {result.stderr[:500]}...",
                    'result_dir': None
                }
            
            return {
                'success': True,
                'error': None,
                'result_dir': os.path.join(output_dir, "result")
            }
            
        except subprocess.TimeoutExpired:
            return {
                'success': False,
                'error': "SACToR Docker ç¿»è¯‘è¶…æ—¶ (10åˆ†é’Ÿ)",
                'result_dir': None
            }
        except Exception as e:
            return {
                'success': False,
                'error': f"SACToR Docker ç¿»è¯‘å‡ºé”™: {e}",
                'result_dir': None
            }
    
    def verify_translation_result(self, result_dir: str) -> Dict:
        """éªŒè¯ç¿»è¯‘ç»“æœ"""
        try:
            verification_results = {
                'unidiomatic': {'success': False, 'details': {}},
                'idiomatic': {'success': False, 'details': {}},
                'overall': False,
                'test_count': 0
            }
            
            # æŸ¥æ‰¾ç¿»è¯‘ç»“æœ
            unidiomatic_dir = os.path.join(result_dir, "translated_code_unidiomatic")
            idiomatic_dir = os.path.join(result_dir, "translated_code_idiomatic")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç¿»è¯‘ç»“æœ
            if os.path.exists(unidiomatic_dir):
                verification_results['unidiomatic'] = {'success': True, 'details': {'exists': True}}
            
            if os.path.exists(idiomatic_dir):
                verification_results['idiomatic'] = {'success': True, 'details': {'exists': True}}
                
                # è®¡ç®—æµ‹è¯•æ•°é‡
                test_samples_path = os.path.join(result_dir, "..", "test_samples.json")
                if os.path.exists(test_samples_path):
                    with open(test_samples_path, 'r') as f:
                        test_samples = json.load(f)
                    verification_results['test_count'] = len(test_samples)
            
            # ç»¼åˆç»“æœ
            verification_results['overall'] = (
                verification_results['unidiomatic']['success'] and 
                verification_results['idiomatic']['success']
            )
            
            return verification_results
            
        except Exception as e:
            return {
                'unidiomatic': {'success': False, 'error': str(e)},
                'idiomatic': {'success': False, 'error': str(e)},
                'overall': False,
                'test_count': 0
            }
    
    def translate_and_verify(self, c_file_path: str, output_dir: str) -> Dict:
        """ç¿»è¯‘å’ŒéªŒè¯å•ä¸ª C æ–‡ä»¶"""
        try:
            print(f"ğŸ¯ é¢„ç”Ÿæˆæµ‹è¯•ç¿»è¯‘: {os.path.basename(c_file_path)}")
            
            # 1. ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹åˆ›å»ºæµ‹è¯•é…ç½®
            test_task_path, test_samples_path = self.create_test_config_with_pre_generated(c_file_path, output_dir)
            
            # 2. ä½¿ç”¨ SACToR Docker è¿›è¡Œç¿»è¯‘
            translation_result = self.translate_with_sactor_docker(c_file_path, output_dir, test_task_path)
            
            if not translation_result['success']:
                return {
                    'success': False,
                    'error': translation_result['error'],
                    'verification': None,
                    'test_count': 0
                }
            
            # 3. éªŒè¯ç¿»è¯‘ç»“æœ
            verification_results = self.verify_translation_result(translation_result['result_dir'])
            
            return {
                'success': True,
                'error': None,
                'verification': verification_results,
                'test_count': verification_results.get('test_count', 0),
                'result_dir': translation_result['result_dir']
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"ç¿»è¯‘å¤±è´¥: {e}",
                'verification': None,
                'test_count': 0
            }
    
    def batch_translate(self, dataset_dirs: List[str], output_base_dir: str, max_files: int = None) -> Dict:
        """æ‰¹é‡ç¿»è¯‘"""
        all_c_files = []
        
        # æ”¶é›†æ‰€æœ‰ C æ–‡ä»¶
        for dataset_dir in dataset_dirs:
            if os.path.exists(dataset_dir):
                c_files = [os.path.join(dataset_dir, f) for f in os.listdir(dataset_dir) if f.endswith('.c')]
                all_c_files.extend(c_files)
        
        # é™åˆ¶å¤„ç†æ–‡ä»¶æ•°é‡ï¼ˆå¦‚æœæŒ‡å®šï¼‰
        if max_files is not None and len(all_c_files) > max_files:
            all_c_files = all_c_files[:max_files]
            print(f"âš ï¸ é™åˆ¶å¤„ç†å‰ {max_files} ä¸ªæ–‡ä»¶")
        
        total_files = len(all_c_files)
        print(f"ğŸš€ å¼€å§‹é¢„ç”Ÿæˆæµ‹è¯•æ‰¹é‡ç¿»è¯‘ {total_files} ä¸ª C æ–‡ä»¶")
        
        results = {
            'total': total_files,
            'success': 0,
            'failed': 0,
            'verified': 0,
            'pre_generated_used': 0,
            'default_used': 0,
            'details': [],
            'start_time': time.time()
        }
        
        for i, c_file_path in enumerate(all_c_files):
            print(f"\nğŸ“ å¤„ç†æ–‡ä»¶ {i+1}/{total_files}: {os.path.basename(c_file_path)}")
            
            # ä¸ºæ¯ä¸ªæ–‡ä»¶åˆ›å»ºè¾“å‡ºç›®å½•
            relative_path = os.path.relpath(c_file_path, os.path.dirname(dataset_dirs[0]))
            file_output_dir = os.path.join(output_base_dir, relative_path.replace('.c', ''))
            os.makedirs(file_output_dir, exist_ok=True)
            
            # ç¿»è¯‘å’ŒéªŒè¯
            result = self.translate_and_verify(c_file_path, file_output_dir)
            
            if result['success']:
                results['success'] += 1
                if result['verification'] and result['verification']['overall']:
                    results['verified'] += 1
            
            # ç»Ÿè®¡æµ‹è¯•ç”¨ä¾‹æ¥æº
            if self.find_pre_generated_tests(c_file_path):
                results['pre_generated_used'] += 1
            else:
                results['default_used'] += 1
            
            results['details'].append({
                'file': os.path.basename(c_file_path),
                'directory': os.path.dirname(c_file_path),
                'success': result['success'],
                'verified': result['verification']['overall'] if result['verification'] else False,
                'test_count': result['test_count'],
                'error': result['error']
            })
            
            results['failed'] = results['total'] - results['success']
            
            # æ¯å¤„ç† 10 ä¸ªæ–‡ä»¶ä¿å­˜ä¸€æ¬¡è¿›åº¦
            if (i + 1) % 10 == 0:
                self._save_progress(results, output_base_dir, i + 1)
        
        results['end_time'] = time.time()
        results['duration'] = results['end_time'] - results['start_time']
        
        return results
    
    def _save_progress(self, results: Dict, output_base_dir: str, processed_count: int):
        """ä¿å­˜è¿›åº¦"""
        progress_file = os.path.join(output_base_dir, f"progress_{processed_count}.json")
        with open(progress_file, 'w') as f:
            json.dump(results, f, indent=2)
        print(f"ğŸ’¾ è¿›åº¦å·²ä¿å­˜: {processed_count}/{results['total']} æ–‡ä»¶")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    dataset_dirs = [
        "/home/changdi/sactor-datasets/Project_CodeNet/selected_data_raw/argv",
        "/home/changdi/sactor-datasets/Project_CodeNet/selected_data_raw/scanf"
    ]
    output_base_dir = "/home/changdi/sactor-datasets/sactor_pregen_translations"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_base_dir, exist_ok=True)
    
    # ç»Ÿè®¡æ€»æ–‡ä»¶æ•°å’Œé¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹è¦†ç›–
    total_files = 0
    pregen_argv = 0
    pregen_scanf = 0
    
    for dataset_dir in dataset_dirs:
        if os.path.exists(dataset_dir):
            c_files = [f for f in os.listdir(dataset_dir) if f.endswith('.c')]
            total_files += len(c_files)
            
            # ç»Ÿè®¡é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹è¦†ç›–
            if "argv" in dataset_dir:
                pregen_argv = len(os.listdir("/home/changdi/sactor-datasets/Project_CodeNet/generated_tests/argv"))
            elif "scanf" in dataset_dir:
                pregen_scanf = len(os.listdir("/home/changdi/sactor-datasets/Project_CodeNet/generated_tests/scanf"))
    
    print(f"ğŸ“ æ‰¾åˆ°æ€»è®¡ {total_files} ä¸ª C æ–‡ä»¶")
    print(f"   - argv ç›®å½•: {len([f for f in os.listdir(dataset_dirs[0]) if f.endswith('.c')])} ä¸ªæ–‡ä»¶")
    print(f"   - scanf ç›®å½•: {len([f for f in os.listdir(dataset_dirs[1]) if f.endswith('.c')])} ä¸ªæ–‡ä»¶")
    print(f"ğŸ¯ é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹è¦†ç›–:")
    print(f"   - argv: {pregen_argv} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"   - scanf: {pregen_scanf} ä¸ªæµ‹è¯•æ–‡ä»¶")
    print(f"ğŸ”§ å°†ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹è¿›è¡Œç¿»è¯‘")
    
    # åˆ›å»ºç¿»è¯‘å™¨
    translator = PreGeneratedTestTranslator()
    
    try:
        # æ‰¹é‡ç¿»è¯‘
        results = translator.batch_translate(dataset_dirs, output_base_dir, max_files=None)
        
        # è¾“å‡ºç»“æœç»Ÿè®¡
        print(f"\nğŸ“Š SACToR é¢„ç”Ÿæˆæµ‹è¯•æ‰¹é‡ç¿»è¯‘ç»“æœ:")
        print(f"æ€»æ–‡ä»¶æ•°: {results['total']}")
        print(f"ç¿»è¯‘æˆåŠŸ: {results['success']}")
        print(f"ç¿»è¯‘å¤±è´¥: {results['failed']}")
        print(f"éªŒè¯é€šè¿‡: {results['verified']}")
        print(f"ä½¿ç”¨é¢„ç”Ÿæˆæµ‹è¯•: {results['pre_generated_used']}")
        print(f"ä½¿ç”¨é»˜è®¤æµ‹è¯•: {results['default_used']}")
        print(f"å¤„ç†æ—¶é—´: {results['duration']:.2f} ç§’")
        print(f"æˆåŠŸç‡: {results['success']/results['total']*100:.1f}%")
        print(f"éªŒè¯ç‡: {results['verified']/results['total']*100:.1f}%")
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        results_file = os.path.join(output_base_dir, "sactor_pregen_results.json")
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        return results
        
    finally:
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        if hasattr(translator, 'temp_dir') and os.path.exists(translator.temp_dir):
            shutil.rmtree(translator.temp_dir)

if __name__ == "__main__":
    main()
