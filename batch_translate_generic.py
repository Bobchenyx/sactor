#!/usr/bin/env python3
"""
é€šç”¨æ‰¹é‡ç¿»è¯‘è„šæœ¬ - æ”¯æŒä»»æ„ C æ–‡ä»¶æ•°æ®é›†
å¯ä»¥ç¿»è¯‘ test_4k_accept æˆ– test_4k_accept_34 ç­‰ä¸åŒæ•°æ®é›†
"""

import os
import json
import subprocess
import shutil
import tempfile
import threading
import time
import argparse
from concurrent.futures import ThreadPoolExecutor, as_completed


class GenericTranslator:
    def __init__(self, c_files_dir, json_dir, output_base_dir, num_tests=6):
        self.c_files_dir = c_files_dir
        self.json_dir = json_dir
        self.output_base_dir = output_base_dir
        self.sactor_docker_image = "sactor"
        self.print_lock = threading.Lock()
        self.num_tests = num_tests
        
        # ç»Ÿè®¡
        self.total_tasks = 0
        self.completed = 0
        self.failed = 0
        self.skipped = 0
        
        print("=" * 80)
        print("ğŸš€ é€šç”¨æ‰¹é‡ç¿»è¯‘å·¥å…·")
        print("=" * 80)
        print(f"ğŸ“ C æ–‡ä»¶ç›®å½•: {self.c_files_dir}")
        print(f"ğŸ“ JSON ç›®å½•: {self.json_dir}")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_base_dir}")
        print(f"ğŸ§ª æµ‹è¯•ç”¨ä¾‹æ•°: {self.num_tests} ä¸ª")
        print("=" * 80)
    
    def collect_translation_tasks(self):
        """æ”¶é›†æ‰€æœ‰ç¿»è¯‘ä»»åŠ¡"""
        tasks = []
        
        # éå†æ‰€æœ‰é—®é¢˜ç›®å½•
        problem_dirs = sorted([d for d in os.listdir(self.c_files_dir) 
                              if os.path.isdir(os.path.join(self.c_files_dir, d)) 
                              and d.startswith('p')])
        
        for problem_id in problem_dirs:
            c_dir = os.path.join(self.c_files_dir, problem_id, 'C')
            if not os.path.exists(c_dir):
                continue
            
            # æ‰¾åˆ°è¯¥é—®é¢˜çš„ç¬¬ä¸€ä¸ª JSON æ–‡ä»¶
            json_problem_dir = os.path.join(self.json_dir, problem_id, 'C')
            json_file = None
            
            if os.path.exists(json_problem_dir):
                json_files = sorted([f for f in os.listdir(json_problem_dir) 
                                   if f.endswith('.json')])
                if json_files:
                    json_file = os.path.join(json_problem_dir, json_files[0])
            
            if not json_file:
                continue  # æ²¡æœ‰ JSON å°±è·³è¿‡
            
            # è·å–æ‰€æœ‰ C æ–‡ä»¶
            c_files = sorted([f for f in os.listdir(c_dir) if f.endswith('.c')])
            
            for c_filename in c_files:
                c_file = os.path.join(c_dir, c_filename)
                submission_id = c_filename.replace('.c', '')
                
                # è¾“å‡ºç›®å½•ç»“æ„: output_base_dir/problem_id/Rust/submission_id/
                output_dir = os.path.join(self.output_base_dir, problem_id, 
                                         'Rust', submission_id, 
                                         'translated_code_unidiomatic')
                
                tasks.append({
                    'task_id': f"{problem_id}/{submission_id}",
                    'problem_id': problem_id,
                    'submission_id': submission_id,
                    'c_file': c_file,
                    'json_file': json_file,
                    'output_dir': os.path.dirname(output_dir)
                })
        
        return tasks
    
    def translate_single_task(self, task):
        """ç¿»è¯‘å•ä¸ªä»»åŠ¡"""
        task_id = task['task_id']
        c_file = task['c_file']
        json_file = task['json_file']
        output_dir = task['output_dir']
        
        # æ£€æŸ¥æ˜¯å¦å·²ç»ç¿»è¯‘è¿‡ï¼ˆåªæ£€æŸ¥ combined.rsï¼‰
        combined_rust_file = os.path.join(output_dir, 'translated_code_unidiomatic', 'combined.rs')
        
        if os.path.exists(combined_rust_file) and os.path.getsize(combined_rust_file) > 100:
            with self.print_lock:
                self.skipped += 1
                progress = f"[{self.completed + self.failed + self.skipped}/{self.total_tasks}]"
                print(f"â­ï¸  {progress} {task_id} - å·²å­˜åœ¨ï¼Œè·³è¿‡", flush=True)
            return {'status': 'skipped', 'task_id': task_id}
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºtest_task.json
        temp_dir = f"/tmp/sactor_translate_{task['submission_id']}"
        os.makedirs(temp_dir, exist_ok=True)
        
        try:
            # ä»test_samples.jsonåˆ›å»ºtest_task.json
            with open(json_file, 'r') as f:
                test_samples = json.load(f)
            
            # åªä½¿ç”¨æŒ‡å®šæ•°é‡çš„æµ‹è¯•ç”¨ä¾‹
            test_samples_limited = test_samples[:self.num_tests]
            
            # å¤åˆ¶test_samples.jsonåˆ°ä¸´æ—¶ç›®å½•ï¼ˆåªåŒ…å«æŒ‡å®šæ•°é‡ï¼‰
            test_samples_path = os.path.join(temp_dir, 'test_samples.json')
            with open(test_samples_path, 'w') as f:
                json.dump(test_samples_limited, f, indent=2)
            
            # åˆ›å»ºtest_task.json - åº”è¯¥æ˜¯å‘½ä»¤åˆ—è¡¨ï¼ˆåªä½¿ç”¨æŒ‡å®šæ•°é‡ï¼‰
            test_task = []
            for i in range(len(test_samples_limited)):
                test_task.append({
                    "command": f"sactor run-tests --type bin ./test_samples.json %t {i} --feed-as-stdin",
                    "test_id": i
                })
            
            test_task_path = os.path.join(temp_dir, 'test_task.json')
            with open(test_task_path, 'w') as f:
                json.dump(test_task, f, indent=2)
            
            # å‡†å¤‡ç›®å½•
            c_dir = os.path.dirname(c_file)
            c_filename = os.path.basename(c_file)
            os.makedirs(output_dir, exist_ok=True)
            
            # Dockerå‘½ä»¤
            docker_cmd = [
                "docker", "run", "--rm",
                "-v", f"{c_dir}:/input:ro",
                "-v", f"{temp_dir}:/work:ro",
                "-v", f"{output_dir}:/output",
                "-v", "/home/changdi/sactor/sactor.toml:/app/sactor.toml:ro",
                "-w", "/work",
                self.sactor_docker_image,
                "translate",
                "--type", "bin",
                "--unidiomatic-only",
                "--result-dir", "/output",
                f"/input/{c_filename}",
                "/work/test_task.json"
            ]
            
            # æ‰§è¡Œç¿»è¯‘
            with self.print_lock:
                print(f"\n{'='*60}")
                print(f"ğŸ”„ å¼€å§‹ç¿»è¯‘: {task_id}")
                print(f"   Cæ–‡ä»¶: {c_file}")
                print(f"   JSON: {json_file}")
                print(f"   è¾“å‡º: {output_dir}")
                print(f"{'='*60}\n")
            
            process = subprocess.Popen(
                docker_cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1
            )
            
            output_lines = []
            for line in process.stdout:
                with self.print_lock:
                    print(line, end='', flush=True)
                output_lines.append(line)
            
            process.wait()
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            shutil.rmtree(temp_dir, ignore_errors=True)
            
            # æ£€æŸ¥ç»“æœ
            if os.path.exists(combined_rust_file) and os.path.getsize(combined_rust_file) > 100:
                with self.print_lock:
                    self.completed += 1
                    progress = f"[{self.completed + self.failed}/{self.total_tasks}]"
                    print(f"\nâœ… {progress} {task_id} - ç¿»è¯‘æˆåŠŸ\n")
                return {'status': 'success', 'task_id': task_id}
            else:
                with self.print_lock:
                    self.failed += 1
                    progress = f"[{self.completed + self.failed}/{self.total_tasks}]"
                    print(f"\nâŒ {progress} {task_id} - ç¿»è¯‘å¤±è´¥ (æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶)")
                    print(f"   æœŸæœ›æ–‡ä»¶: {combined_rust_file}")
                    print(f"   Dockerè¿”å›ç : {process.returncode}")
                    if output_lines:
                        print(f"   æœ€å10è¡Œè¾“å‡º:")
                        for line in output_lines[-10:]:
                            print(f"     {line.rstrip()}")
                    print()
                return {'status': 'failed', 'task_id': task_id}
                
        except Exception as e:
            shutil.rmtree(temp_dir, ignore_errors=True)
            with self.print_lock:
                self.failed += 1
                progress = f"[{self.completed + self.failed}/{self.total_tasks}]"
                print(f"âŒ {progress} {task_id}: {str(e)}")
            return {'status': 'error', 'task_id': task_id, 'error': str(e)}
    
    def run(self, workers=4):
        """æ‰§è¡Œæ‰¹é‡ç¿»è¯‘"""
        # æ”¶é›†ä»»åŠ¡
        tasks = self.collect_translation_tasks()
        if not tasks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¿»è¯‘ä»»åŠ¡")
            return
        
        self.total_tasks = len(tasks)
        
        print(f"\nâš™ï¸  é…ç½®:")
        print(f"   å¹¶å‘æ•°: {workers}")
        print(f"   æµ‹è¯•ç”¨ä¾‹æ•°: {self.num_tests} ä¸ª")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.output_base_dir, exist_ok=True)
        
        print(f"\nğŸ”„ å¼€å§‹ç¿»è¯‘ {self.total_tasks} ä¸ªä»»åŠ¡...\n")
        
        start_time = time.time()
        
        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œç¿»è¯‘
        with ThreadPoolExecutor(max_workers=workers) as executor:
            futures = {executor.submit(self.translate_single_task, task): task 
                      for task in tasks}
            
            for future in as_completed(futures):
                try:
                    result = future.result()
                except Exception as e:
                    with self.print_lock:
                        self.failed += 1
                        print(f"âŒ ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}")
        
        elapsed = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        print("\n" + "=" * 80)
        print("ğŸ“Š ç¿»è¯‘å®Œæˆç»Ÿè®¡")
        print("=" * 80)
        print(f"âœ… æˆåŠŸ: {self.completed}")
        print(f"â­ï¸  è·³è¿‡ (å·²å­˜åœ¨): {self.skipped}")
        print(f"âŒ å¤±è´¥: {self.failed}")
        print(f"ğŸ“ æ€»ä»»åŠ¡: {self.total_tasks}")
        print(f"â±ï¸  ç”¨æ—¶: {elapsed:.1f} ç§’")
        if elapsed > 0:
            print(f"ğŸ“ˆ é€Ÿåº¦: {self.total_tasks / elapsed:.2f} ä¸ª/ç§’")
        print("=" * 80)


def main():
    parser = argparse.ArgumentParser(
        description='é€šç”¨æ‰¹é‡ç¿»è¯‘å·¥å…· - æ”¯æŒä»»æ„ C æ–‡ä»¶æ•°æ®é›†',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

1. ç¿»è¯‘ test_4k_accept (ç¬¬1-2ä¸ªAccepted):
   python3 batch_translate_generic.py \\
       --c-files /home/changdi/CodeNet/test_4k_accept \\
       --json-files /home/changdi/sactor/generated_tests \\
       --output /home/changdi/sactor/translated_rust_4k \\
       --workers 10

2. ç¿»è¯‘ test_4k_accept_34 (ç¬¬3-4ä¸ªAccepted):
   python3 batch_translate_generic.py \\
       --c-files /home/changdi/CodeNet/test_4k_accept_34 \\
       --json-files /home/changdi/sactor/generated_tests \\
       --output /home/changdi/sactor/translated_rust_4k_34 \\
       --workers 10

3. è‡ªå®šä¹‰æµ‹è¯•ç”¨ä¾‹æ•°é‡:
   python3 batch_translate_generic.py \\
       --c-files /home/changdi/CodeNet/test_4k_accept \\
       --json-files /home/changdi/sactor/generated_tests \\
       --output /home/changdi/sactor/translated_rust_4k \\
       --num-tests 10 \\
       --workers 8
        """
    )
    
    parser.add_argument('--c-files', required=True, 
                       help='Cæ–‡ä»¶ç›®å½• (ä¾‹å¦‚: /home/changdi/CodeNet/test_4k_accept)')
    parser.add_argument('--json-files', required=True,
                       help='JSONæµ‹è¯•æ–‡ä»¶ç›®å½• (ä¾‹å¦‚: /home/changdi/sactor/generated_tests)')
    parser.add_argument('--output', required=True,
                       help='è¾“å‡ºç›®å½• (ä¾‹å¦‚: /home/changdi/sactor/translated_rust_4k)')
    parser.add_argument('--workers', type=int, default=4, 
                       help='å¹¶å‘æ•° (é»˜è®¤: 4)')
    parser.add_argument('--num-tests', type=int, default=6,
                       help='ä½¿ç”¨çš„æµ‹è¯•ç”¨ä¾‹æ•°é‡ (é»˜è®¤: 6)')
    
    args = parser.parse_args()
    
    # éªŒè¯ç›®å½•å­˜åœ¨
    if not os.path.exists(args.c_files):
        print(f"âŒ Cæ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {args.c_files}")
        return
    
    if not os.path.exists(args.json_files):
        print(f"âŒ JSONæ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {args.json_files}")
        return
    
    translator = GenericTranslator(
        c_files_dir=args.c_files,
        json_dir=args.json_files,
        output_base_dir=args.output,
        num_tests=args.num_tests
    )
    translator.run(workers=args.workers)


if __name__ == "__main__":
    main()

